{
  "version": "1.0.0",
  "name": "Skills",
  "description": "Agent skills for AI coding assistants \u2014 built for OpenClaw, Claude Code, Cursor, and Codex",
  "repository": "https://github.com/san-npm/skills-ws",
  "website": "https://skills-ws.vercel.app",
  "skills": [
    {
      "name": "seo-geo",
      "version": "1.0.0",
      "description": "SEO & GEO (Generative Engine Optimization) for websites. Optimize for AI search engines and traditional search.",
      "color": "10B981",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Technical SEO audits with actionable fixes",
        "Generative Engine Optimization for ChatGPT, Perplexity, Gemini, Google AI Overview",
        "Schema markup generation (10+ JSON-LD types)",
        "Keyword research and competitor gap analysis",
        "E-E-A-T assessment and improvement",
        "Core Web Vitals diagnostics",
        "International SEO and hreflang setup"
      ],
      "useCases": [
        "Audit a website for technical SEO issues",
        "Optimize content for AI search engines",
        "Generate structured data for rich snippets",
        "Research keywords and content gaps"
      ],
      "content": "# SEO & GEO Optimization v2\n\n**GEO = Generative Engine Optimization** \u2014 AI engines cite sources, not rank pages. Being cited is the new #1.\n\n## Workflow\n\n### 1. Technical SEO Audit\n\nRun the free audit script:\n```bash\npython3 scripts/seo_audit.py \"https://example.com\"\n```\n\nManual quick checks:\n```bash\ncurl -sL \"URL\" | grep -E \"<title>|<meta name=\\\"description\\\"|application/ld\\+json\" | head -20\ncurl -s \"URL/robots.txt\"\ncurl -s \"URL/sitemap.xml\" | head -50\n```\n\nEnsure AI bots allowed in robots.txt: `Googlebot`, `Bingbot`, `PerplexityBot`, `ChatGPT-User`, `ClaudeBot`, `GPTBot`, `anthropic-ai`.\n\nFull technical checklist (Core Web Vitals, crawl budget, mobile-first): references/technical-seo.md\n\n### 2. Keyword Research\n\nWith DataForSEO API (`DATAFORSEO_LOGIN` + `DATAFORSEO_PASSWORD` env vars):\n```bash\npython3 scripts/keyword_research.py \"keyword\" --location 2840 --language en\npython3 scripts/competitor_gap.py \"yourdomain.com\" \"competitor.com\"\npython3 scripts/serp_analysis.py \"target keyword\"\n```\n\nWithout API \u2014 use web search for volume/difficulty estimates.\n\nCluster by intent: informational \u2192 blog, transactional \u2192 landing pages, navigational \u2192 product pages. Full methodology: references/keyword-research.md\n\n### 3. GEO Optimization\n\nApply **Princeton 9 GEO Methods** \u2014 best combo: **Fluency + Statistics**:\n\n| Method | Boost | Action |\n|--------|-------|--------|\n| Cite Sources | +40% | Authoritative references with links |\n| Statistics | +37% | Specific numbers and data points |\n| Quotations | +30% | Expert quotes with attribution |\n| Authoritative Tone | +25% | Confident expert language |\n| Simplify | +20% | Plain language for complex topics |\n| Technical Terms | +18% | Domain-specific vocabulary |\n| Fluency | +15-30% | Readability and flow |\n| ~~Keyword Stuffing~~ | **-10%** | **NEVER** |\n\nStructure content for AI citation: answer-first format, clear H1>H2>H3, bullet/numbered lists, tables, short paragraphs (2-3 sentences), FAQ sections with schema.\n\nPlatform-specific strategies: references/geo-optimization.md\n\n### 4. E-E-A-T Signals\n\n- Author bios with credentials on every article\n- Link to primary sources and studies\n- Display trust signals (certifications, awards, reviews)\n- Include first-hand experience and original data\n- Visible last-updated timestamps\n- Build topical authority through content clusters\n\nFull guide: references/eeat-guide.md\n\n### 5. Schema Markup (JSON-LD)\n\nGenerate structured data for every page type:\n- `WebPage`/`Article` \u2014 content pages\n- `FAQPage` \u2014 FAQ sections (+40% AI visibility)\n- `HowTo` \u2014 tutorials and guides\n- `Product` + `AggregateRating` \u2014 product pages\n- `Organization`/`LocalBusiness` \u2014 about/contact pages\n- `SoftwareApplication` \u2014 tools and apps\n- `BreadcrumbList` \u2014 navigation\n- `VideoObject` \u2014 video content\n- `Review`/`AggregateRating` \u2014 review pages\n\nTemplates: references/schema-templates.md\n\nValidate at: `https://search.google.com/test/rich-results?url={url}`\n\n### 6. On-Page SEO\n\n```html\n<title>{Primary Keyword} \u2014 {Brand} | {Secondary}</title>\n<meta name=\"description\" content=\"{150-160 chars with keyword}\">\n<meta property=\"og:title\" content=\"{Title}\">\n<meta property=\"og:description\" content=\"{Description}\">\n<meta property=\"og:image\" content=\"{1200x630 image URL}\">\n<meta name=\"twitter:card\" content=\"summary_large_image\">\n```\n\nChecklist:\n- H1 contains primary keyword (one H1 per page)\n- Images have descriptive alt text with keywords\n- Internal links to related content (3-5 per page)\n- External links use `rel=\"noopener noreferrer\"`\n- URL is short, descriptive, hyphenated\n- Page loads under 3 seconds\n- Mobile-friendly responsive design\n\n### 7. International SEO\n\nFor multilingual sites, implement hreflang:\n```html\n<link rel=\"alternate\" hreflang=\"en\" href=\"https://example.com/en/\" />\n<link rel=\"alternate\" hreflang=\"fr\" href=\"https://example.com/fr/\" />\n<link rel=\"alternate\" hreflang=\"x-default\" href=\"https://example.com/\" />\n```\n\nFull guide: references/international-seo.md\n\n### 8. Security Audit\n\nScan competitor and referenced URLs with VirusTotal:\n```bash\nvt scan url \"https://competitor.com\"\nvt url \"https://competitor.com\" --include=last_analysis_stats\n```\n\nFlag any URLs with detections > 0 in recommendations.\n\n## References\n\n- references/technical-seo.md \u2014 Core Web Vitals, crawlability, indexing\n- references/geo-optimization.md \u2014 AI search strategies per platform\n- references/schema-templates.md \u2014 JSON-LD for 10+ page types\n- references/keyword-research.md \u2014 Clustering, intent mapping, gap analysis\n- references/eeat-guide.md \u2014 E-E-A-T signals and implementation\n- references/international-seo.md \u2014 hreflang, geo-targeting, multilingual",
      "installs": 656
    },
    {
      "name": "content-strategy",
      "version": "1.0.0",
      "description": "Plan content strategy, decide what to create, figure out what topics to cover for SaaS and software products.",
      "color": "6366F1",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Topic cluster and pillar page planning",
        "Content calendar generation",
        "Competitor content audit and gap analysis",
        "Data-driven topic scoring matrix",
        "Content ROI frameworks",
        "Editorial workflow design"
      ],
      "useCases": [
        "Plan a 90-day content roadmap for a SaaS blog",
        "Identify content gaps vs competitors",
        "Build topic clusters around target keywords",
        "Score and prioritize content ideas by potential impact"
      ],
      "content": "# Content Strategy v2\n\n## Workflow\n\n### 1. Content Audit\n\nInventory existing content:\n- URL, title, word count, publish date, last updated\n- Organic traffic (from GA4/Search Console)\n- Target keyword and current ranking\n- Content type (blog, guide, landing page, case study)\n- Quality score (1-5): accuracy, depth, freshness\n\nFlag: thin content (<500 words), outdated (>12 months), cannibalized (multiple pages targeting same keyword).\n\n### 2. Competitor Content Analysis\n\nFor each competitor:\n1. Run `site:competitor.com` to estimate indexed page count\n2. Identify their top-performing content (Ahrefs/SEMrush or manual research)\n3. Map their content clusters and topic coverage\n4. Find gaps: topics they cover that you don't\n5. Find opportunities: topics neither of you covers well\n\n### 3. Topic Scoring Matrix\n\nScore each topic idea (1-5 on each, total out of 25):\n\n| Factor | Weight | Description |\n|--------|--------|-------------|\n| Search Volume | 5 | Monthly search demand |\n| Business Relevance | 5 | How close to your product/sale |\n| Competition | 5 | Inverse of keyword difficulty |\n| Expertise Match | 5 | Your team's ability to write authoritatively |\n| Content Gap | 5 | Lack of good existing content online |\n\nPrioritize topics scoring 18+ first.\n\n### 4. Topic Cluster Design\n\nBuild pillar-cluster model:\n\n```\nPillar Page: \"Complete Guide to {Topic}\" (3000+ words)\n\u251c\u2500\u2500 Cluster: \"How to {subtopic 1}\" (1500+ words)\n\u251c\u2500\u2500 Cluster: \"{Topic} vs {Alternative}\" (1500+ words)\n\u251c\u2500\u2500 Cluster: \"Best {Topic} tools\" (2000+ words)\n\u251c\u2500\u2500 Cluster: \"{Topic} for {audience}\" (1500+ words)\n\u2514\u2500\u2500 Cluster: \"{Topic} examples\" (1500+ words)\n```\n\nRules:\n- Every cluster page links to its pillar page\n- Pillar page links to all cluster pages\n- Cluster pages interlink where relevant\n- One pillar per major topic area\n\n### 5. Content Calendar\n\nBuild a 90-day calendar:\n- Week 1-4: Foundation content (pillar pages, core landing pages)\n- Week 5-8: Cluster content (supporting blog posts)\n- Week 9-12: Amplification content (case studies, comparisons, guest posts)\n\nCadence: 2-4 pieces/week for growing sites, 1-2/week for maintenance.\n\nTemplate in references/content-frameworks.md.\n\n### 6. Content ROI Tracking\n\nTrack per piece:\n- Production cost (time + money)\n- Organic traffic after 90 days\n- Leads/conversions attributed\n- Revenue attributed (if measurable)\n- Cost per lead from content\n\n## References\n\n- references/content-frameworks.md \u2014 Pillar/cluster model, scoring matrix, calendar templates, editorial workflow",
      "installs": 302
    },
    {
      "name": "copywriting",
      "version": "1.0.0",
      "description": "Write, rewrite, or improve marketing copy for any page \u2014 homepage, landing, pricing, feature, about, or product pages.",
      "color": "F59E0B",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Headline frameworks: PAS, AIDA, 4Us, BAB, and 20+ more",
        "CTA optimization and placement strategy",
        "Voice and tone guidelines",
        "Before/after copy rewrites with reasoning",
        "50+ proven copy patterns from swipe file"
      ],
      "useCases": [
        "Rewrite a homepage hero section for higher conversion",
        "Write pricing page copy that addresses objections",
        "Craft feature page copy from product specs",
        "Improve CTAs across an entire site"
      ],
      "content": "# Copywriting v2\n\nWrite marketing copy that converts. Every page element has a job \u2014 make sure it does it.\n\n## Core Frameworks\n\n### PAS (Problem-Agitate-Solve)\n1. **Problem**: Name the pain the reader feels\n2. **Agitate**: Make the pain vivid and urgent\n3. **Solve**: Present your product as the answer\n\n### AIDA (Attention-Interest-Desire-Action)\n1. **Attention**: Bold headline or surprising stat\n2. **Interest**: Expand with relevant details\n3. **Desire**: Show benefits and social proof\n4. **Action**: Clear, specific CTA\n\n### BAB (Before-After-Bridge)\n1. **Before**: Current painful state\n2. **After**: Dream outcome achieved\n3. **Bridge**: Your product is how they get there\n\n### 4Us (Useful-Urgent-Unique-Ultra-specific)\nScore every headline 1-4 on each U. Aim for 12+.\n\nFull frameworks and 50+ swipe patterns: references/frameworks.md\n\n## Page-by-Page Playbook\n\n### Homepage\n- Hero: One clear value proposition (what + for whom + why different)\n- Subheadline: Expand on the benefit or address the \"how\"\n- Social proof bar: logos, numbers, or testimonial\n- 3 feature blocks: benefit-first headlines, not feature labels\n- Final CTA section: restate the value prop with urgency\n\n### Landing Page\n- One goal per page (no navigation distractions)\n- Headline matches the ad/link that brought them\n- Benefits > features (what it does FOR them)\n- Social proof close to CTA\n- Single, repeated CTA button\n\n### Pricing Page\n- Anchor with the most expensive plan first (or highlight recommended)\n- Name plans by persona (\"Starter\", \"Growth\", \"Scale\") not size\n- Feature comparison table with checkmarks\n- FAQ section addressing objections\n- Money-back guarantee near CTA\n\n### Feature Page\n- Lead with the outcome, not the feature name\n- Show don't tell: screenshots, demos, examples\n- Compare old way vs new way\n- Testimonial from someone who uses THIS feature\n- CTA: try this specific feature\n\n## CTA Optimization\n\nRules:\n- Use first person: \"Start my free trial\" > \"Start your free trial\"\n- Be specific: \"Get the report\" > \"Submit\"\n- Add value: \"Create my account (free)\" > \"Sign up\"\n- Reduce risk: \"Try free for 14 days \u2014 no credit card\"\n- One primary CTA per page section\n\n## Voice & Tone\n\nDefine for every brand:\n- **Voice** (constant): Professional? Casual? Playful? Authoritative?\n- **Tone** (varies by context): Landing page = confident, Error page = helpful, Email = friendly\n\nRules:\n- Write at 6th-8th grade reading level\n- Short sentences (15-20 words average)\n- Active voice always\n- \"You\" more than \"we\"\n- Cut every word that doesn't earn its place\n\n## References\n\n- references/frameworks.md \u2014 PAS, AIDA, BAB, PASTOR, StoryBrand + 50 swipe patterns\n- references/swipe-file.md \u2014 Proven copy examples by page type",
      "installs": 1326
    },
    {
      "name": "page-cro",
      "version": "1.0.0",
      "description": "Optimize, improve, or increase conversions on any marketing page \u2014 homepage, landing, pricing, feature pages.",
      "color": "EF4444",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Page-level conversion audit with prioritized fixes",
        "Above-the-fold optimization",
        "Social proof and trust signal placement",
        "Friction analysis and removal",
        "Mobile conversion optimization",
        "A/B test hypothesis generation"
      ],
      "useCases": [
        "Audit a landing page and get prioritized improvement list",
        "Increase homepage-to-signup conversion rate",
        "Optimize pricing page layout and copy",
        "Generate A/B test ideas for underperforming pages"
      ],
      "content": "# Page CRO v2\n\n## Audit Workflow\n\n### 1. Above the Fold\nFirst screen must contain:\n- Clear value proposition (what + for whom + why different)\n- Primary CTA (visible without scrolling)\n- Trust signal (logo bar, testimonial snippet, or metric)\n- Relevant hero image/video (not stock photos)\n\n### 2. Page Structure\nOptimal section order for landing pages:\n1. Hero (value prop + CTA)\n2. Social proof bar (logos or metrics)\n3. Problem statement (pain they feel)\n4. Solution (how you solve it)\n5. Features/benefits (3-4 max, benefit-first)\n6. Social proof (testimonials, case studies)\n7. How it works (3 steps)\n8. Pricing or offer\n9. FAQ (address objections)\n10. Final CTA (restate value prop)\n\n### 3. Trust Signals\n- Customer logos (known brands first)\n- Metrics: \"Used by X+ companies\" / \"Y% improvement\"\n- Testimonials with photo, name, title, company\n- Review scores (G2, Trustpilot, etc.)\n- Security badges (SOC2, GDPR, SSL)\n- Money-back guarantee badge near CTA\n\n### 4. CTA Optimization\n- Button color: contrast with page (test red vs green vs blue)\n- Button text: first person, specific (\"Start my free trial\")\n- Reduce risk: \"No credit card required\", \"Cancel anytime\"\n- One primary CTA per section, same action throughout\n\n## A/B Testing\n\n### Sample Size Calculator\n```\nMinimum sample = 16 \u00d7 p \u00d7 (1-p) / MDE\u00b2\np = baseline conversion rate (e.g., 0.05 for 5%)\nMDE = minimum detectable effect (e.g., 0.2 for 20% relative improvement)\n```\n\nFor 5% baseline, 20% relative improvement: ~6,400 visitors per variant.\n\n### Statistical Significance\n- z = (p1 - p2) / sqrt(p_pool \u00d7 (1 - p_pool) \u00d7 (1/n1 + 1/n2))\n- Significant if z > 1.96 (95% confidence)\n- Run for minimum 2 full weeks (capture weekly patterns)\n- Don't stop early on promising results\n\nFull testing guide: references/ab-testing.md\n\n## Heatmap Interpretation\n\n- **Red zones**: High attention \u2014 put important content here\n- **Cold zones**: Low attention \u2014 move or remove content\n- **False bottoms**: If users stop scrolling, add visual continuity cues\n- **Rage clicks**: Frustration indicator \u2014 element looks clickable but isn't\n- **F-pattern/Z-pattern**: Place key elements along natural scan path\n\n## Page Speed Impact\n- 1s \u2192 3s load time: bounce rate increases 32%\n- 1s \u2192 5s load time: bounce rate increases 90%\n- Each 100ms improvement: +1% conversion rate\n- Mobile speed matters more (slower connections)\n\n## References\n\n- references/ab-testing.md \u2014 Complete A/B testing guide with calculators\n- references/cro-patterns.md \u2014 30+ proven conversion patterns",
      "installs": 1203
    },
    {
      "name": "email-sequence",
      "version": "1.0.0",
      "description": "Create or optimize email sequences, drip campaigns, automated flows, and lifecycle email programs.",
      "color": "8B5CF6",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Complete sequence templates: welcome, onboarding, re-engagement, abandoned cart, win-back",
        "Subject line optimization with proven formulas",
        "Deliverability best practices",
        "Segmentation and trigger logic",
        "Email copy frameworks"
      ],
      "useCases": [
        "Build a 7-email onboarding sequence for a SaaS product",
        "Optimize subject lines for higher open rates",
        "Design a re-engagement campaign for churned users",
        "Set up automated lifecycle email triggers"
      ],
      "content": "# Email Sequence v2\n\n## Sequence Design\n\n### 1. Define the Sequence\n\nEvery sequence needs:\n- **Trigger**: What action starts the sequence (signup, purchase, inactivity)\n- **Goal**: One clear objective (activate, convert, retain, re-engage)\n- **Length**: 3-7 emails typically\n- **Cadence**: Days between emails (vary by urgency)\n- **Exit condition**: What stops the sequence (conversion, unsubscribe, another trigger)\n\n### 2. Email Structure\n\nEvery email follows:\n```\nSubject Line (30-50 chars, mobile-friendly)\nPreview Text (40-90 chars, complements subject)\n---\nOpening Line (personal, specific, no \"I hope this finds you well\")\nBody (one idea per email, scannable, short paragraphs)\nCTA (one primary action, button or link)\nP.S. (optional \u2014 high readability, good for secondary CTA)\n```\n\n### 3. Subject Line Optimization\n\nFormulas:\n- Question: \"Struggling with {pain point}?\"\n- Number: \"{Number} ways to {outcome}\"\n- Curiosity gap: \"The {topic} mistake you're probably making\"\n- Personal: \"{First name}, quick question\"\n- Urgency: \"Last chance: {offer} expires tonight\"\n- Social proof: \"{Number} people already {action}\"\n- How-to: \"How to {outcome} in {timeframe}\"\n\nRules:\n- 30-50 characters (mobile truncation at ~40)\n- No ALL CAPS (spam filter trigger)\n- Avoid: \"free\", \"act now\", \"limited time\" in first emails\n- Test emoji vs no emoji (audience-dependent)\n- Preview text is part of the subject \u2014 make them work together\n\n### 4. Sequence Templates\n\nTemplates for 6 sequence types: references/sequence-templates.md\n\n### 5. Deliverability\n\nCritical for reaching inboxes: references/deliverability.md\n\n### 6. Segmentation\n\nSegment by:\n- **Behavior**: pages visited, emails opened/clicked, features used\n- **Demographics**: role, company size, industry\n- **Lifecycle stage**: trial, active, at-risk, churned\n- **Engagement**: highly engaged, passive, dormant\n\nRule: The more personalized the segment, the higher the conversion rate. Aim for segments of 500+ for statistical significance.\n\n## Metrics\n\n| Metric | Good | Great | Action if Low |\n|--------|------|-------|---------------|\n| Open Rate | 20-25% | 30%+ | Fix subject lines, sender name, send time |\n| Click Rate | 2-5% | 5%+ | Fix CTA, email body, offer relevance |\n| Reply Rate | 1-3% | 5%+ | More personal tone, better questions |\n| Unsubscribe | <0.5% | <0.2% | Better targeting, reduce frequency |\n| Bounce Rate | <2% | <0.5% | Clean list, verify emails |\n\n## References\n\n- references/sequence-templates.md \u2014 6 complete sequence templates with timing\n- references/deliverability.md \u2014 SPF, DKIM, DMARC, warm-up, reputation",
      "installs": 1114
    },
    {
      "name": "paid-ads",
      "version": "1.0.0",
      "description": "Paid advertising campaigns on Google Ads, Meta, LinkedIn, Twitter/X. Strategy, copy, targeting, optimization.",
      "color": "F97316",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Campaign structure design per platform",
        "Ad copy formulas with character limit compliance",
        "Audience targeting and lookalike strategies",
        "Bidding strategy selection and optimization",
        "ROAS tracking and optimization",
        "A/B testing frameworks for ad creative",
        "Negative keyword lists and brand safety"
      ],
      "useCases": [
        "Set up a Google Ads campaign structure from scratch",
        "Write Meta ad copy variants for A/B testing",
        "Build LinkedIn audience targeting for B2B SaaS",
        "Optimize ad spend allocation across platforms"
      ],
      "content": "# Paid Ads v2\n\n## Campaign Structure\n\n### Google Ads\n```\nAccount\n\u251c\u2500\u2500 Campaign (budget + geo + bidding)\n\u2502   \u251c\u2500\u2500 Ad Group (keyword theme)\n\u2502   \u2502   \u251c\u2500\u2500 Keywords (10-20 per group)\n\u2502   \u2502   \u251c\u2500\u2500 Ads (3-5 responsive search ads)\n\u2502   \u2502   \u2514\u2500\u2500 Extensions (sitelinks, callouts, structured snippets)\n\u2502   \u2514\u2500\u2500 Ad Group 2...\n\u2514\u2500\u2500 Campaign 2...\n```\n\n### Meta (Facebook/Instagram)\n```\nAd Account\n\u251c\u2500\u2500 Campaign (objective: conversions/traffic/awareness)\n\u2502   \u251c\u2500\u2500 Ad Set (audience + placement + budget + schedule)\n\u2502   \u2502   \u251c\u2500\u2500 Ad (creative + copy + CTA)\n\u2502   \u2502   \u2514\u2500\u2500 Ad 2...\n\u2502   \u2514\u2500\u2500 Ad Set 2 (different audience)\n\u2514\u2500\u2500 Campaign 2...\n```\n\n## Ad Copy Formulas\n\n### Google Search Ads (30 char headlines, 90 char descriptions)\n- H1: {Keyword} \u2014 {Benefit}\n- H2: {Social Proof} | {Offer}\n- H3: {CTA} \u2014 {Risk Reversal}\n- D1: {Expand on benefit}. {Specific result}. {CTA with urgency}.\n- D2: {Address objection}. {Trust signal}. {Secondary CTA}.\n\n### Meta Ads\n- **Hook** (first line, before \"See more\"): Bold claim, question, or stat\n- **Body**: Problem \u2192 Solution \u2192 Proof \u2192 CTA\n- **CTA button**: Match to funnel stage (Learn More \u2192 top, Sign Up \u2192 mid, Shop Now \u2192 bottom)\n\nPlatform specs and character limits: references/platform-specs.md\n\n## Audience Targeting\n\n### Google\n- Keywords: exact [keyword], phrase \"keyword\", broad +keyword\n- Negative keywords: exclude irrelevant searches (add weekly)\n- In-market audiences: people actively researching your category\n- Custom intent: target by URLs and keywords competitors use\n\n### Meta\n- Core audiences: demographics + interests + behaviors\n- Custom audiences: website visitors, email list, video viewers, engagers\n- Lookalike audiences: 1% (best quality) to 10% (more reach) of source\n- Exclusions: existing customers, converters, irrelevant audiences\n\n### LinkedIn\n- Job title + seniority + company size + industry\n- Matched audiences: website retargeting, email list, lookalikes\n- Tip: Layer job function + seniority for best results\n\n## Bidding Strategy\n\n| Goal | Google Strategy | Meta Strategy |\n|------|----------------|---------------|\n| Conversions | Target CPA or Maximize Conversions | Lowest Cost or Cost Cap |\n| Revenue | Target ROAS | Minimum ROAS |\n| Traffic | Maximize Clicks | Lowest Cost (link clicks) |\n| Awareness | Target Impression Share | Reach or ThruPlay |\n\nStart with automated bidding, switch to manual only when you have 30+ conversions/month of data.\n\n## Budget Framework\n\n- Test budget: $50-100/day per campaign minimum (need statistical significance)\n- Scale: Increase 20% every 3-5 days (avoid learning phase resets)\n- Split: 70% proven campaigns, 20% testing, 10% experimental\n\n## A/B Testing\n\nTest one variable at a time:\n1. **Headlines** (highest impact)\n2. **Creative/image** (Meta, LinkedIn)\n3. **CTA** (button text and offer)\n4. **Audience** (different targeting)\n5. **Landing page** (post-click experience)\n\nMinimum: 1000 impressions and 100 clicks per variant before declaring winner.\n\n## Retargeting\n\nFunnel-based retargeting:\n- **1-3 days**: Cart abandoners \u2192 urgency/discount\n- **3-7 days**: Product page visitors \u2192 social proof/benefits\n- **7-14 days**: Blog readers \u2192 lead magnet/free trial\n- **14-30 days**: Homepage visitors \u2192 brand story/value prop\n- **30-90 days**: All visitors \u2192 seasonal offers/new features\n\nFrequency cap: 3-5 impressions per person per week.\n\n## References\n\n- references/platform-specs.md \u2014 Character limits, image sizes, placements per platform\n- references/ad-copy-formulas.md \u2014 30+ proven ad copy templates",
      "installs": 771
    },
    {
      "name": "signup-flow-cro",
      "version": "1.0.0",
      "description": "Optimize signup, registration, account creation, or trial activation flows for higher conversion.",
      "color": "14B8A6",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Signup flow audit with friction scoring",
        "Progressive profiling and multi-step form design",
        "Social login and SSO integration patterns",
        "Trial activation optimization",
        "Onboarding handoff design",
        "Drop-off analysis and recovery"
      ],
      "useCases": [
        "Reduce signup form abandonment rate",
        "Design a frictionless trial-to-paid flow",
        "Add progressive profiling to reduce upfront fields",
        "Optimize the signup-to-first-value path"
      ],
      "content": "# Signup Flow CRO v2\n\n## Signup Form Optimization\n\n### Field Reduction\nEvery additional field reduces conversion 5-10%. Minimum viable signup:\n- **Best**: Email only (or social login)\n- **Good**: Email + password\n- **Acceptable**: Email + password + name\n- **Risky**: Email + password + name + company + phone\n\nAsk everything else AFTER signup (progressive profiling).\n\n### Social Login\nOffer in order of conversion impact:\n1. Google (highest adoption)\n2. GitHub (dev tools)\n3. Apple (mobile apps)\n4. Microsoft (enterprise)\n5. SSO/SAML (enterprise, behind \"Enterprise login\" link)\n\nPlace social login ABOVE email form (most users prefer it).\n\n### Password UX\n- Show password strength indicator (real-time)\n- Allow show/hide password toggle\n- Minimum 8 chars, no arbitrary rules (no \"must include uppercase + number + symbol\")\n- Support password managers (proper autocomplete attributes)\n\n### Email Verification\n- Don't block access before verification (let them in, remind later)\n- Verification email within 10 seconds\n- Clear subject: \"Verify your {Product} email\"\n- One-click verification button (no codes to type)\n- Resend option visible after 30 seconds\n- Fallback: magic link or code entry\n\n## Multi-Step Forms\nWhen you MUST collect more info:\n1. Step 1: Email + password (create account)\n2. Step 2: Role + company size (personalize experience)\n3. Step 3: Use case or goals (tailor onboarding)\n\nRules:\n- Show progress indicator\n- Allow skipping non-essential steps\n- Save progress (don't lose data on back button)\n- Each step has value for the user (personalization, not just your data collection)\n\n## Post-Signup Handoff\nWithin 5 seconds of signup:\n- Redirect to first-value action (not empty dashboard)\n- Welcome modal with 1-2 question setup wizard\n- Start onboarding checklist\n\n## References\n\n- references/signup-patterns.md \u2014 Signup form patterns and examples\n- references/friction-checklist.md \u2014 25-point friction audit",
      "installs": 619
    },
    {
      "name": "popup-cro",
      "version": "1.0.0",
      "description": "Create or optimize popups, modals, overlays, slide-ins, and banners for conversion. Exit intent, lead capture, announcements.",
      "color": "A855F7",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Exit intent popup design and timing",
        "Lead capture modal optimization",
        "Scroll-triggered and time-delayed overlays",
        "Mobile-friendly popup patterns",
        "A/B test frameworks for popup variants",
        "Frequency capping and user experience balance"
      ],
      "useCases": [
        "Design an exit-intent popup that converts without annoying users",
        "Build a lead capture modal with progressive disclosure",
        "Optimize popup timing and frequency rules",
        "Create announcement banners for product launches"
      ],
      "content": "# Popup CRO v2\n\n## Popup Types\n\n| Type | Trigger | Best For |\n|------|---------|----------|\n| Exit intent | Mouse moves to close/back | Last-chance offers, lead capture |\n| Scroll-triggered | 50-75% scroll depth | Engaged readers, content upgrades |\n| Time delay | 15-30 seconds on page | Returning visitors, announcements |\n| Click-triggered | Button/link click | Gated content, detailed info |\n| Slide-in | Corner, scroll-triggered | Less intrusive lead capture |\n| Top bar | Always visible | Announcements, promotions |\n\n## Design Rules\n\n- **One popup per page visit** (never stack)\n- **Easy close**: visible X button, click outside to dismiss, Escape key\n- **Mobile-friendly**: full-width on mobile, thumb-reachable close button\n- **Frequency cap**: Don't show again for 7-30 days after dismiss\n- **Respect \"no\"**: If they close it, don't show same offer again soon\n\n## Trigger Timing\n\n- **New visitors**: Time delay (30s) or scroll (50%)\n- **Returning visitors**: Exit intent (they already know you)\n- **Blog readers**: Scroll-triggered at 60% (they're engaged)\n- **Pricing page**: Exit intent with discount or chat offer\n- **Cart page**: Exit intent with urgency/discount\n\n## Copy Framework\n\n```\n[Headline: Benefit or offer]\n[1-2 line supporting text]\n[Form: email field + CTA button]\n[Trust text: \"No spam. Unsubscribe anytime.\"]\n[Close link: \"No thanks, I don't want {benefit}\"]\n```\n\nThe \"no thanks\" text should make saying no feel slightly silly (but never manipulative).\n\n## Templates and trigger rules: references/popup-templates.md\n\n## References\n\n- references/trigger-rules.md \u2014 When to show which popup type\n- references/popup-templates.md \u2014 Copy and design templates",
      "installs": 556
    },
    {
      "name": "programmatic-seo",
      "version": "1.0.0",
      "description": "Create SEO-driven pages at scale using templates and data. Directory pages, location pages, comparison pages.",
      "color": "0EA5E9",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Template page architecture for scale",
        "Data source integration and content generation",
        "Internal linking automation",
        "Canonical and pagination strategy",
        "Quality control at scale",
        "Location page and comparison page templates"
      ],
      "useCases": [
        "Build 500+ city-specific landing pages from a template",
        "Create comparison pages for competitor alternatives",
        "Generate integration directory pages from API data",
        "Set up automated internal linking between programmatic pages"
      ],
      "content": "# Programmatic SEO v2\n\n## When to Use pSEO\n\nGood candidates:\n- Location + service combinations (\"plumber in {city}\")\n- Tool/product comparisons (\"{Tool A} vs {Tool B}\")\n- Integration pages (\"{Product} + {Integration}\")\n- Glossary/definition pages (\"{Term} definition\")\n- Directory/listing pages (\"{Category} in {Location}\")\n- Alternative pages (\"{Product} alternatives\")\n\nBad candidates (will get penalized):\n- Thin pages with just swapped city names\n- Auto-generated content with no unique value\n- Doorway pages targeting variations of one keyword\n\n## Pipeline\n\n### 1. Data Collection\n- Identify all variable combinations (cities \u00d7 services, tools \u00d7 tools)\n- Gather unique data per page (statistics, local info, product details)\n- Validate data quality (no empty fields, accurate information)\n\n### 2. Template Design\n\nEach template needs:\n- **Unique intro** (not just \"{city} + {service}\" boilerplate)\n- **Data-driven content** (real statistics, comparisons, facts per entity)\n- **User value** (answers a real question, not just keyword targeting)\n- **Internal links** (to related pages within the programmatic set)\n- **Schema markup** (appropriate type per page category)\n\n### 3. Quality Thresholds\n- Minimum 500 unique words per page (not counting boilerplate)\n- At least 3 data points unique to that page\n- No more than 40% shared content across pages\n- Every page must answer at least one question a real user would have\n\n### 4. Internal Linking\n- Hub pages link to all children (e.g., \"Plumbers\" \u2192 all city pages)\n- Child pages link to hub and 3-5 siblings\n- Cross-link between related categories\n- Breadcrumb navigation on every page\n\n### 5. Indexing Strategy\n- XML sitemap for all programmatic pages\n- Noindex thin pages until they have enough content\n- Monitor Search Console for \"Crawled \u2014 currently not indexed\"\n- Submit in batches (1000-5000 pages at a time)\n\n## Page Templates\n\nDetailed templates by type: references/template-patterns.md\nData pipeline architecture: references/data-pipeline.md\n\n## References\n\n- references/template-patterns.md \u2014 Templates for each page type\n- references/data-pipeline.md \u2014 Data collection and generation pipelines",
      "installs": 1928
    },
    {
      "name": "growth-hacking",
      "version": "1.0.0",
      "description": "Growth hacking strategies and tactics. Viral loops, referral programs, activation funnels, retention hooks.",
      "color": "22C55E",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Viral loop design and K-factor optimization",
        "Referral program mechanics and incentive structure",
        "Activation funnel mapping and optimization",
        "Retention hook design (habit loops, streaks, notifications)",
        "Growth experiment prioritization (ICE/RICE scoring)",
        "Channel-specific growth playbooks"
      ],
      "useCases": [
        "Design a viral referral loop for a SaaS product",
        "Map and optimize the activation funnel",
        "Prioritize growth experiments with ICE scoring",
        "Build retention mechanics that reduce churn"
      ],
      "content": "# Growth Hacking\n\n## AARRR Framework (Pirate Metrics)\n\n| Stage | Metric | Target |\n|-------|--------|--------|\n| **Acquisition** | New signups/visitors | Channel-dependent |\n| **Activation** | % completing key action | 40-60% |\n| **Retention** | Day 7/30 retention | 25%/15%+ |\n| **Revenue** | Conversion to paid | 5-15% |\n| **Referral** | Viral coefficient (K) | >0.5, ideally >1 |\n\nFocus on fixing the leakiest stage first.\n\n## Viral Loop Design\n\nTypes of viral loops:\n1. **Inherent**: Product requires sharing (Slack, Zoom, Dropbox shared folders)\n2. **Incentivized**: Reward for referring (Dropbox storage, Uber credits)\n3. **Word-of-mouth**: Product so good people talk about it\n4. **Content**: User-created content gets shared (Canva, Spotify Wrapped)\n\nViral coefficient K = invites \u00d7 conversion rate. K>1 = exponential growth.\n\nDesign details: references/viral-mechanics.md\n\n## Product-Led Growth (PLG)\n\nKey principles:\n- Free tier or trial with real value (not crippled)\n- Self-serve onboarding (no sales call needed)\n- Aha moment within first session\n- Usage-based expansion (natural path to paid)\n- In-product sharing and collaboration\n\nPLG playbook: references/plg-playbook.md\n\n## Experimentation\n\n### ICE Framework\nScore each experiment 1-10:\n- **Impact**: How big is the potential upside?\n- **Confidence**: How sure are you it'll work?\n- **Ease**: How easy is it to implement?\n\nTotal = I + C + E. Run highest scores first.\n\n### RICE Framework\n- **Reach**: How many users affected per quarter?\n- **Impact**: Minimal (0.25) \u2192 Massive (3)\n- **Confidence**: Low (50%) \u2192 High (100%)\n- **Effort**: Person-weeks to build\n\nScore = (Reach \u00d7 Impact \u00d7 Confidence) / Effort\n\nDetails: references/experiment-frameworks.md\n\n## Retention Hooks\n\n- **Habit loop**: Trigger \u2192 Action \u2192 Variable Reward \u2192 Investment\n- **Progress mechanics**: Streaks, levels, completion percentage\n- **Loss aversion**: \"You'll lose your streak\" / \"Your data will be deleted\"\n- **Social proof**: \"Your team is using this\" / \"3 colleagues joined\"\n- **Notification strategy**: Email, push, in-app \u2014 context-dependent timing\n\n## References\n\n- references/viral-mechanics.md \u2014 Viral loop templates and examples\n- references/plg-playbook.md \u2014 PLG implementation guide\n- references/experiment-frameworks.md \u2014 ICE, RICE, PIE frameworks with templates",
      "installs": 330
    },
    {
      "name": "landing-page-builder",
      "version": "1.0.0",
      "description": "Build high-converting landing pages from scratch. Copy, layout, CTAs, social proof, and responsive design.",
      "color": "3B82F6",
      "category": "design",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Full landing page architecture from hero to footer",
        "Conversion-optimized section ordering",
        "Social proof and testimonial patterns",
        "Responsive design with mobile-first approach",
        "CTA placement and design strategy",
        "Above-the-fold optimization"
      ],
      "useCases": [
        "Build a complete SaaS landing page from product specs",
        "Design a product launch page with countdown and waitlist",
        "Create a webinar registration page",
        "Build a comparison landing page for paid ads"
      ],
      "content": "# Landing Page Builder\n\nBuild complete landing pages section by section. Copy + design + code in one flow.\n\n## Page Blueprint\n\nEvery high-converting landing page follows this structure:\n\n### 1. Hero Section\n```\n[Logo + minimal nav]\nH1: Primary value proposition (what + for whom)\nSubtitle: Expand on the benefit or \"how\"\n[Primary CTA button]   [Secondary CTA: \"See demo\"]\nTrust bar: \"Trusted by X+ companies\" + 3-5 logos\n[Hero image/screenshot/video]\n```\n\n### 2. Problem Section\n```\nH2: \"The problem with {current approach}\"\n3 pain points with icons:\n  - Pain 1: specific frustration\n  - Pain 2: specific frustration\n  - Pain 3: specific frustration\n```\n\n### 3. Solution Section\n```\nH2: \"How {Product} solves this\"\n3 benefits (NOT features):\n  - Benefit 1: outcome they get + supporting screenshot\n  - Benefit 2: outcome they get + supporting screenshot\n  - Benefit 3: outcome they get + supporting screenshot\n```\n\n### 4. Social Proof Section\n```\nH2: \"Trusted by teams at\"\n[Logo grid: 6-8 recognizable brands]\n3 testimonial cards: photo + quote + name + title + company\nKey metric: \"X% average improvement in {outcome}\"\n```\n\n### 5. How It Works\n```\nH2: \"Get started in 3 steps\"\nStep 1: [Icon] Title \u2192 Description\nStep 2: [Icon] Title \u2192 Description\nStep 3: [Icon] Title \u2192 Description\n```\n\n### 6. Features Grid\n```\nH2: \"Everything you need to {outcome}\"\n6 feature cards: icon + title + 1-line description\n```\n\n### 7. Pricing (optional)\n```\nH2: \"Simple, transparent pricing\"\n2-3 plan cards with: name, price, features list, CTA\nHighlight recommended plan\nFAQ below pricing\n```\n\n### 8. FAQ Section\n```\nH2: \"Frequently asked questions\"\n5-8 accordion items addressing common objections\nInclude FAQPage schema markup\n```\n\n### 9. Final CTA\n```\nH2: Restate value proposition\nSubtitle: Urgency or risk reversal\n[Primary CTA button \u2014 same as hero]\n```\n\n## Section templates with Tailwind code: references/section-templates.md\n\n## Conversion principles: references/conversion-principles.md\n\n## References\n\n- references/section-templates.md \u2014 HTML/Tailwind code for each section type\n- references/conversion-principles.md \u2014 Design principles for conversion",
      "installs": 322
    },
    {
      "name": "lead-scoring",
      "version": "1.0.0",
      "description": "Design and implement lead scoring models. Qualify leads based on behavior, demographics, and engagement.",
      "color": "DC2626",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Scoring model design (behavioral + demographic)",
        "Engagement scoring rules and thresholds",
        "MQL/SQL qualification criteria",
        "Score decay and recency weighting",
        "CRM integration patterns",
        "Score calibration and validation"
      ],
      "useCases": [
        "Build a lead scoring model for a B2B SaaS funnel",
        "Define MQL and SQL criteria based on engagement data",
        "Set up score decay rules for inactive leads",
        "Integrate scoring with HubSpot or Salesforce workflows"
      ],
      "content": "# Lead Scoring\n\n## Scoring Model Design\n\n### Two-Axis Model\nScore leads on two independent axes:\n1. **Fit Score** (0-100): How well they match your ICP (demographics)\n2. **Engagement Score** (0-100): How actively they interact (behavior)\n\nCombine: `Total Score = (Fit \u00d7 0.4) + (Engagement \u00d7 0.6)`\n\n### Fit Score (Demographics)\n\n| Signal | Points | Example |\n|--------|--------|---------|\n| Company size matches ICP | +20 | 50-500 employees |\n| Industry match | +15 | SaaS, fintech |\n| Job title/seniority | +20 | VP+, Director, C-level |\n| Budget range confirmed | +15 | >$50K ARR potential |\n| Geography match | +10 | Target market |\n| Tech stack match | +10 | Uses compatible tools |\n| Revenue range match | +10 | $5M-$50M ARR |\n\n### Engagement Score (Behavior)\n\n| Signal | Points | Decay |\n|--------|--------|-------|\n| Pricing page visit | +20 | -5/week |\n| Demo request | +30 | None |\n| Free trial signup | +25 | -5/week inactive |\n| Case study download | +10 | -3/week |\n| Blog post read | +2 | -1/week |\n| Email open | +1 | -1/week |\n| Email click | +5 | -2/week |\n| Webinar attended | +15 | -3/week |\n| Multiple sessions (3+) | +10 | -2/week |\n| Returned after 30d absence | +15 | -5/week |\n\n### Score Decay\nApply weekly decay to prevent stale high scores. A lead who visited pricing 3 months ago isn't hot anymore.\n\n### Thresholds\n\n| Score | Classification | Action |\n|-------|---------------|--------|\n| 0-30 | Cold lead | Nurture sequence |\n| 31-50 | Warm lead | Targeted content |\n| 51-70 | MQL | Marketing-qualified, alert SDR |\n| 71-85 | SQL | Sales-qualified, direct outreach |\n| 86-100 | Hot | Immediate sales attention |\n\n## Qualification Frameworks\n\nDetails: references/scoring-models.md\n\n## References\n\n- references/scoring-models.md \u2014 BANT, CHAMP, MEDDIC frameworks with implementation guides\n- references/signal-weights.md \u2014 Calibrating signal weights with historical data",
      "installs": 583
    },
    {
      "name": "local-seo",
      "version": "1.0.0",
      "description": "Local SEO optimization. Google Business Profile, local citations, reviews, location pages, map pack ranking.",
      "color": "059669",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Google Business Profile optimization",
        "Local citation building and NAP consistency",
        "Review management and response templates",
        "Location page content strategy",
        "Map pack ranking factors and optimization",
        "Local schema markup (LocalBusiness, FAQ)"
      ],
      "useCases": [
        "Optimize a Google Business Profile for local search",
        "Build location-specific landing pages for multi-location business",
        "Create a review acquisition and response strategy",
        "Audit and fix local citation inconsistencies"
      ],
      "content": "# Local SEO\n\n## Google Business Profile (GBP)\n\n### Setup Checklist\n- [ ] Claim and verify listing\n- [ ] Correct business name (no keyword stuffing)\n- [ ] Primary + secondary categories (most specific first)\n- [ ] Complete address (or service area for mobile businesses)\n- [ ] Phone number (local, not toll-free)\n- [ ] Website URL (to location-specific page if multi-location)\n- [ ] Business hours (keep updated, mark holidays)\n- [ ] Business description (750 chars, natural keywords)\n- [ ] 10+ high-quality photos (exterior, interior, team, products)\n- [ ] Enable messaging and booking if applicable\n\n### Ongoing Optimization\n- Post weekly (offers, events, updates, products)\n- Respond to ALL reviews within 24 hours\n- Add new photos monthly\n- Update seasonal hours\n- Use Google Posts for promotions\n- Answer Q&A section proactively\n\n## NAP Consistency\n\nNAP = Name, Address, Phone. Must be IDENTICAL everywhere:\n- Google Business Profile\n- Website footer and contact page\n- All directory listings\n- Social media profiles\n- Schema markup\n\nEven small variations hurt (\"St.\" vs \"Street\", \"Suite\" vs \"Ste.\").\n\n## Local Citations\n\nSubmit to top directories: references/citation-sources.md\n\n## Local Schema\n\nAdd LocalBusiness schema to every location page: references/local-schema.md\n\n## Review Management\n\n- Ask happy customers for reviews (email 1 week after purchase/service)\n- Respond to negative reviews: acknowledge, apologize, offer resolution offline\n- Never buy fake reviews (Google penalizes heavily)\n- Display reviews on your website (with Review schema)\n- Target: 4.0+ average, 50+ reviews for competitive niches\n\n## Geo-Targeted Content\n\nFor each location:\n- Unique location page (not boilerplate with city swapped)\n- Local landmarks, events, community references\n- Local testimonials from that area\n- Embedded Google Map\n- Location-specific schema markup\n\n## References\n\n- references/gbp-optimization.md \u2014 Detailed GBP guide\n- references/citation-sources.md \u2014 Top directory sites\n- references/local-schema.md \u2014 LocalBusiness JSON-LD",
      "installs": 1095
    },
    {
      "name": "marketing-analytics",
      "version": "1.0.0",
      "description": "Marketing analytics setup and optimization. GA4, attribution, dashboards, KPIs, funnel analysis.",
      "color": "7C3AED",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "GA4 setup and event taxonomy design",
        "UTM strategy and naming conventions",
        "Attribution modeling (first-touch, last-touch, linear, time-decay)",
        "KPI dashboard design and metric selection",
        "Funnel analysis and drop-off diagnostics",
        "Conversion tracking implementation"
      ],
      "useCases": [
        "Set up GA4 with a structured event taxonomy",
        "Design a UTM naming convention for all marketing channels",
        "Build a marketing KPI dashboard",
        "Implement multi-touch attribution for paid campaigns"
      ],
      "content": "# Marketing Analytics\n\n## GA4 Setup\n\n### Event Taxonomy\n\nDesign events in a consistent `object_action` pattern:\n```\npage_view, session_start, first_visit\nform_submit, form_start, form_error\nbutton_click, link_click, cta_click\nsignup_start, signup_complete\npurchase_start, purchase_complete\nfeature_use, feature_activate\ncontent_view, content_scroll, content_share\n```\n\n### Key Events (Conversions)\nMark as conversions in GA4:\n- `signup_complete` \u2014 new account creation\n- `purchase_complete` \u2014 transaction\n- `demo_request` \u2014 high-intent lead\n- `trial_start` \u2014 trial activation\n- `contact_submit` \u2014 contact form\n\n### Enhanced Measurement\nEnable in GA4 settings: page views, scrolls, outbound clicks, site search, file downloads, video engagement.\n\n### Custom Dimensions\n- `user_type`: free, trial, paid, churned\n- `traffic_source_detail`: granular source tracking\n- `content_category`: blog, docs, landing, product\n- `experiment_variant`: A/B test tracking\n\nFull setup guide: references/ga4-setup.md\n\n## UTM Strategy\n\n### Convention\n```\nutm_source = platform (google, facebook, linkedin, newsletter)\nutm_medium = channel type (cpc, social, email, referral)\nutm_campaign = campaign name (spring-sale-2026, product-launch)\nutm_content = creative variant (hero-image-a, cta-blue)\nutm_term = keyword (only for paid search)\n```\n\n### Rules\n- All lowercase, hyphens not underscores\n- Consistent naming across team (document in shared sheet)\n- Never use UTMs on internal links (breaks session attribution)\n- Tag every external link: ads, emails, social posts, partner links\n\nFull conventions: references/utm-conventions.md\n\n## Attribution Models\n\n| Model | How It Works | Best For |\n|-------|-------------|----------|\n| Last Click | 100% credit to last touchpoint | Bottom-funnel optimization |\n| First Click | 100% credit to first touchpoint | Understanding acquisition |\n| Linear | Equal credit to all touchpoints | Balanced view |\n| Time Decay | More credit to recent touchpoints | Long sales cycles |\n| Position-Based | 40% first, 40% last, 20% middle | Most balanced default |\n| Data-Driven | ML-based, GA4 default | 1000+ conversions/month |\n\nRecommendation: Use data-driven if you have the volume. Otherwise, position-based is the best default.\n\nDetails: references/attribution-models.md\n\n## KPI Dashboard\n\n### Acquisition\n- Sessions by source/medium\n- New vs returning users\n- Cost per acquisition (CPA) by channel\n- Landing page conversion rates\n\n### Engagement\n- Pages per session\n- Average engagement time\n- Bounce rate by page\n- Scroll depth (25%, 50%, 75%, 100%)\n\n### Conversion\n- Conversion rate by funnel step\n- Drop-off between steps\n- Revenue by attribution model\n- Customer acquisition cost (CAC)\n\n### Retention\n- Cohort retention curves\n- Monthly active users (MAU)\n- Churn rate by cohort\n- Customer lifetime value (CLV)\n\n## References\n\n- references/ga4-setup.md \u2014 Complete GA4 implementation guide\n- references/utm-conventions.md \u2014 UTM naming standards and examples\n- references/attribution-models.md \u2014 Deep dive on each model with examples",
      "installs": 1152
    },
    {
      "name": "crm-builder",
      "version": "1.0.0",
      "description": "Design and implement CRM workflows. Pipeline management, automation, lead nurturing, deal tracking.",
      "color": "2563EB",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Sales pipeline stage design",
        "Automation workflow templates",
        "Lead nurturing sequences",
        "Deal tracking and forecasting",
        "Custom field and property architecture",
        "Integration patterns for common CRM platforms"
      ],
      "useCases": [
        "Design a sales pipeline for a B2B SaaS product",
        "Build automated lead nurturing workflows",
        "Set up deal tracking with revenue forecasting",
        "Create custom CRM properties for better segmentation"
      ],
      "content": "# CRM Builder\n\n## CRM Design Process\n\n### 1. Define Pipeline Stages\n\nStandard B2B SaaS pipeline:\n```\nLead \u2192 MQL \u2192 SQL \u2192 Discovery \u2192 Demo \u2192 Proposal \u2192 Negotiation \u2192 Closed Won/Lost\n```\n\nStandard B2B Services:\n```\nInquiry \u2192 Qualified \u2192 Meeting \u2192 Proposal \u2192 Contract \u2192 Closed Won/Lost\n```\n\nE-commerce/B2C:\n```\nVisitor \u2192 Lead \u2192 Customer \u2192 Repeat \u2192 VIP\n```\n\nRules:\n- Max 7-8 stages (more = confusion)\n- Each stage has clear entry criteria\n- Define required fields per stage (can't advance without them)\n- Set expected time in each stage (flag stalled deals)\n\n### 2. Contact Properties\n\nEssential fields:\n- Name, email, phone, company, job title\n- Lead source (utm_source or manual)\n- Lead score (see lead-scoring skill)\n- Lifecycle stage (subscriber \u2192 lead \u2192 MQL \u2192 SQL \u2192 customer)\n- Owner (assigned sales rep)\n- Last activity date\n- Industry, company size (for segmentation)\n\nCustom fields based on your ICP (Ideal Customer Profile).\n\n### 3. Automation Rules\n\nHigh-impact automations:\n- **Lead assignment**: Route leads by territory, company size, or round-robin\n- **Follow-up reminders**: Alert if no activity for X days\n- **Stage progression**: Auto-move when criteria met (e.g., demo scheduled \u2192 Demo stage)\n- **Win/loss notifications**: Slack/email alert on deal close\n- **Lifecycle updates**: Auto-update contact lifecycle when deal moves\n- **Re-engagement**: Trigger email if deal stalls for X days\n\n### 4. Email Integration\n\n- Sync sent/received emails to contact timeline\n- Log meeting notes and call recordings\n- Track email opens and link clicks\n- Template library for common emails (intro, follow-up, proposal)\n\n### 5. Reporting Dashboard\n\nEssential reports:\n- Pipeline value by stage\n- Win rate by source/owner/month\n- Average deal cycle time\n- Activity metrics (calls, emails, meetings per rep)\n- Revenue forecast (weighted pipeline)\n- Lost deal reasons analysis\n\n### 6. Tool Selection\n\n| Tool | Best For | Price |\n|------|----------|-------|\n| HubSpot Free | Startups, <5 reps | Free \u2192 $50/user/mo |\n| Pipedrive | SMB sales teams | $15-99/user/mo |\n| Salesforce | Enterprise | $25-300/user/mo |\n| Notion/Airtable | Very early stage, custom workflows | Free-$20/user/mo |\n| Close | Inside sales, high-volume calling | $29-149/user/mo |\n\n## References\n\n- references/crm-templates.md \u2014 Pipeline templates by industry, property sets\n- references/automation-recipes.md \u2014 20+ automation workflows",
      "installs": 2269
    },
    {
      "name": "sales-funnel",
      "version": "1.0.0",
      "description": "Design and optimize sales funnels. TOFU/MOFU/BOFU content, qualification stages, conversion paths.",
      "color": "D946EF",
      "category": "conversion",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Full funnel architecture (TOFU/MOFU/BOFU)",
        "Content mapping to funnel stages",
        "Lead qualification stage design",
        "Conversion path optimization",
        "Funnel velocity metrics",
        "Bottleneck identification and resolution"
      ],
      "useCases": [
        "Map content to each stage of the buyer journey",
        "Identify and fix funnel bottlenecks",
        "Design qualification criteria for each funnel stage",
        "Optimize the path from first touch to closed deal"
      ],
      "content": "# Sales Funnel\n\n## Funnel Stages\n\n### TOFU (Top of Funnel) \u2014 Awareness\n- **Goal**: Attract strangers, build audience\n- **Content**: Blog posts, social media, videos, podcasts, infographics\n- **Metrics**: Traffic, impressions, reach, new visitors\n- **CTA**: Subscribe, follow, download free resource\n\n### MOFU (Middle of Funnel) \u2014 Consideration\n- **Goal**: Convert visitors to leads, educate\n- **Content**: Lead magnets, webinars, case studies, email sequences, comparison guides\n- **Metrics**: Leads generated, email subscribers, webinar registrants\n- **CTA**: Download guide, watch demo, join webinar\n\n### BOFU (Bottom of Funnel) \u2014 Decision\n- **Goal**: Convert leads to customers\n- **Content**: Free trials, demos, proposals, consultations, testimonials, ROI calculators\n- **Metrics**: Trial signups, demo requests, conversion rate, revenue\n- **CTA**: Start trial, book demo, get quote, buy now\n\n### Post-Purchase \u2014 Retention & Expansion\n- **Goal**: Retain, upsell, get referrals\n- **Content**: Onboarding, training, check-ins, feature announcements, loyalty programs\n- **Metrics**: Retention rate, NPS, expansion revenue, referral rate\n- **CTA**: Upgrade, refer a friend, leave review\n\n## Lead Magnets by Funnel Stage\n\n| Stage | Lead Magnet | Commitment Level |\n|-------|------------|-----------------|\n| TOFU | Checklist, cheat sheet, template | Low (email only) |\n| TOFU | Quiz, calculator, free tool | Low-medium |\n| MOFU | Ebook, whitepaper, report | Medium |\n| MOFU | Webinar, video course | Medium-high |\n| BOFU | Free trial, demo, consultation | High |\n| BOFU | ROI calculator, custom audit | High |\n\n## Objection Handling\n\nCommon objections and responses: references/objection-handling.md\n\n## Funnel Templates\n\nDetailed funnel blueprints by business type: references/funnel-templates.md\n\n## References\n\n- references/funnel-templates.md \u2014 Complete funnel blueprints\n- references/objection-handling.md \u2014 Top 15 objections with responses",
      "installs": 308
    },
    {
      "name": "smart-contract-auditor",
      "version": "1.0.0",
      "description": "Audit Solidity smart contracts for vulnerabilities, gas optimization, and best practices.",
      "color": "F59E0B",
      "category": "web3",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Vulnerability scanning (reentrancy, overflow, access control)",
        "Gas optimization recommendations",
        "Best practice compliance checks",
        "Common attack vector detection",
        "Upgrade pattern safety analysis",
        "Test coverage assessment"
      ],
      "useCases": [
        "Audit a smart contract before deployment",
        "Identify gas optimization opportunities",
        "Check for common vulnerability patterns",
        "Review upgrade proxy implementation safety"
      ],
      "content": "# Smart Contract Auditor\n\n## Audit Checklist\n\n### 1. Access Control\n- [ ] `onlyOwner` / role-based access on sensitive functions\n- [ ] No unprotected `selfdestruct`\n- [ ] No unprotected proxy upgrade functions\n- [ ] Ownership transfer is two-step (propose + accept)\n- [ ] No default public visibility on state variables\n\n### 2. Reentrancy\n- [ ] External calls are last (checks-effects-interactions pattern)\n- [ ] ReentrancyGuard on functions with external calls + state changes\n- [ ] No cross-function reentrancy via shared state\n\n### 3. Integer Safety\n- [ ] Solidity 0.8+ (built-in overflow protection) or SafeMath\n- [ ] Checked division (no divide by zero)\n- [ ] Casting between types checked for truncation\n\n### 4. Input Validation\n- [ ] All user inputs validated (address != 0, amount > 0)\n- [ ] Array bounds checked\n- [ ] Ether values validated\n\n### 5. Token Handling\n- [ ] SafeERC20 for all token transfers (handles non-standard returns)\n- [ ] Check return values of `transfer` / `transferFrom`\n- [ ] Handle fee-on-transfer tokens if applicable\n- [ ] Handle rebasing tokens if applicable\n\n### 6. Flash Loan Protection\n- [ ] Price oracles use TWAP (not spot price)\n- [ ] Critical functions have minimum time delays\n- [ ] Governance votes have sufficient voting periods\n\n### 7. Front-Running Protection\n- [ ] Commit-reveal for sensitive operations\n- [ ] Maximum slippage parameters on swaps\n- [ ] Deadline parameters on transactions\n\n### 8. Gas Optimization\n- Use `uint256` instead of smaller types (EVM operates on 256-bit)\n- Pack storage variables (multiple small vars in one slot)\n- Use `calldata` instead of `memory` for read-only function params\n- Cache storage reads in local variables\n- Use `++i` instead of `i++`\n- Use custom errors instead of require strings\n\nFull vulnerability catalog: references/vulnerability-catalog.md\nGas optimization guide: references/gas-optimization.md\nComplete audit process: references/audit-checklist.md\n\n## References\n\n- references/vulnerability-catalog.md \u2014 Top 20 vulnerabilities with examples\n- references/gas-optimization.md \u2014 Gas saving patterns\n- references/audit-checklist.md \u2014 Step-by-step audit process",
      "installs": 1014
    },
    {
      "name": "social-media-kit",
      "version": "1.0.0",
      "description": "Create social media content kits. Platform-specific posts, hashtag strategies, content calendars, engagement tactics.",
      "color": "E11D48",
      "category": "marketing",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "features": [
        "Platform-specific content formatting (LinkedIn, Twitter/X, Instagram, TikTok)",
        "Hashtag research and strategy",
        "Content calendar with posting schedule",
        "Engagement tactics and community building",
        "Content repurposing workflows",
        "Social proof and UGC strategy"
      ],
      "useCases": [
        "Create a month of LinkedIn posts from blog content",
        "Build a Twitter/X content calendar with engagement hooks",
        "Design a hashtag strategy for Instagram growth",
        "Repurpose long-form content into social media formats"
      ],
      "content": "# Social Media Kit\n\n## Platform Playbooks\n\n### LinkedIn\n- **Format**: Text posts (1300 chars), articles, carousels (PDF), video\n- **Best performing**: Personal stories, lessons learned, contrarian takes, data insights\n- **Structure**: Hook line \u2192 story/insight \u2192 takeaway \u2192 CTA/question\n- **Posting**: Tuesday-Thursday 8-10am local time\n- **Hashtags**: 3-5 relevant, mix broad (#marketing) and niche (#saasGrowth)\n- **Engagement hack**: Reply to every comment within 1 hour (boosts algorithm)\n\n### Twitter/X\n- **Format**: Tweets (280 chars), threads, images, video\n- **Thread structure**: Hook tweet \u2192 numbered points \u2192 summary \u2192 CTA\n- **Best performing**: Threads (10-15 tweets), hot takes, how-to tips, curated lists\n- **Posting**: 8-10am and 5-7pm local, weekdays\n- **Engagement**: Quote-tweet with added value, reply to big accounts in your niche\n\n### Instagram\n- **Format**: Reels (90s max), carousels (10 slides), stories, posts\n- **Carousels**: Cover slide (hook) \u2192 content slides \u2192 CTA slide\n- **Reels**: Hook in first 1s, value in 15-30s, CTA at end\n- **Hashtags**: 5-10, mix of sizes (10K-500K posts each)\n- **Posting**: Monday, Wednesday, Friday 11am-1pm\n\n### TikTok\n- **Format**: Short video (15-60s optimal)\n- **Hook**: First 1-2 seconds must stop the scroll\n- **Structure**: Hook \u2192 context \u2192 value \u2192 CTA\n- **Trending**: Use trending sounds, adapt trends to your niche\n- **Posting**: 7-9am, 12-3pm, 7-11pm\n\n## Content Repurposing Workflow\n\nOne blog post becomes:\n1. **LinkedIn post** \u2014 key takeaway as personal insight\n2. **Twitter thread** \u2014 main points as numbered thread\n3. **Instagram carousel** \u2014 visual summary (10 slides)\n4. **Short video** \u2014 60s summary for Reels/TikTok\n5. **Email snippet** \u2014 highlight in newsletter\n6. **Quote graphics** \u2014 3-5 pull quotes as images\n\n## Content Calendar Template\n\nSee references/content-calendar.md for weekly planning template.\n\n## References\n\n- references/platform-guides.md \u2014 Detailed specs and best practices per platform\n- references/content-calendar.md \u2014 Weekly planning template with content mix",
      "installs": 1918
    },
    {
      "name": "business-development",
      "description": "BD strategy, partnership frameworks, outreach templates, deal pipeline management, and negotiation playbooks for B2B SaaS.",
      "category": "growth",
      "features": [
        "Partner identification and scoring",
        "Outreach sequence templates",
        "Deal pipeline stage design",
        "Partnership agreement frameworks",
        "Revenue share modeling",
        "BD KPI tracking and reporting"
      ],
      "useCases": [
        "Build a partner outreach program from scratch",
        "Design a BD pipeline with qualification stages",
        "Create partnership pitch decks and one-pagers",
        "Set up co-marketing agreement templates"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Business Development\n\n## Workflow\n\n### 1. Partner Identification\n\n**Scoring matrix \u2014 rate each potential partner 1-5:**\n\n| Criterion | Weight | Score (1-5) |\n|-----------|--------|-------------|\n| Audience overlap | 25% | Does their audience need your product? |\n| Technical fit | 20% | Can you integrate/co-build? |\n| Brand alignment | 15% | Compatible positioning and values? |\n| Reach | 15% | Audience size and engagement |\n| Strategic value | 15% | Opens new market/segment? |\n| Effort to close | 10% | Decision-maker accessibility |\n\n**Weighted score > 3.5 = pursue. 2.5-3.5 = nurture. < 2.5 = skip.**\n\n### 2. Outreach Sequences\n\n**Cold partner outreach (5-touch, 14 days):**\n\n```\nTouch 1 (Day 0) \u2014 Value-first intro\nSubject: [Their product] + [Your product] = [specific outcome]\n\nHi [Name],\n\n[One sentence showing you understand their business].\nI think there's a natural fit between [their product] and [yours]\n\u2014 specifically, [concrete integration/co-marketing idea].\n\n[One sentence on what's in it for them \u2014 traffic, revenue, feature gap filled].\n\nWorth a 15-min call to explore?\n\n[Your name]\n```\n\n```\nTouch 2 (Day 3) \u2014 Case study/proof\nSubject: Re: [original subject]\n\nQuick follow-up \u2014 [similar partnership] drove [specific result]\nfor [company]. Thought the model could work for us too.\n\nHappy to share the details.\n```\n\n```\nTouch 3 (Day 7) \u2014 LinkedIn engagement\nConnect + comment on their recent post with genuine insight.\nThen DM: \"Sent you an email about [topic] \u2014 would love your take.\"\n```\n\n```\nTouch 4 (Day 10) \u2014 New angle\nSubject: Different thought on [their challenge]\n\nNoticed [specific observation about their product/content].\nWe solved that for [X customers] with [approach].\nCould be a co-marketing story worth telling.\n```\n\n```\nTouch 5 (Day 14) \u2014 Breakup\nSubject: Closing the loop\n\nTotally understand if timing isn't right.\nI'll keep an eye on [their product] \u2014 if you ever want\nto explore [partnership type], I'm here.\n```\n\n### 3. Deal Pipeline\n\n| Stage | Definition | Exit criteria | Typical duration |\n|-------|-----------|---------------|-----------------|\n| Identified | Matches partner scoring criteria | Research complete, contact found | 1-2 days |\n| Outreach | First touch sent | Reply received (positive or neutral) | 1-2 weeks |\n| Discovery | Initial call scheduled/completed | Mutual interest confirmed, use case defined | 1-2 weeks |\n| Proposal | Partnership terms drafted | Both sides reviewed, legal involved | 2-4 weeks |\n| Negotiation | Terms being finalized | Agreement on commercial terms | 1-3 weeks |\n| Signed | Contract executed | Integration/campaign kickoff scheduled | 1 week |\n| Live | Partnership active | Revenue/metrics being tracked | Ongoing |\n\n### 4. Partnership Models\n\n| Model | Structure | Best for | Revenue split |\n|-------|-----------|----------|---------------|\n| Referral | Send leads, earn commission | Low-touch, high volume | 10-20% of first year ACV |\n| Reseller | They sell your product | Market expansion | 20-40% margin to partner |\n| Integration | Technical product integration | Sticky, long-term | Rev share on joint customers |\n| Co-marketing | Joint content/events | Brand awareness | Cost share, lead share |\n| White label | They rebrand your product | Enterprise, agencies | 40-60% margin to you |\n\n### 5. Partnership Agreement Essentials\n\n**Non-negotiables in every agreement:**\n- Revenue share % and payment terms (net 30/60)\n- Exclusivity scope (or explicit non-exclusivity)\n- Data sharing and privacy terms (GDPR)\n- Term length and renewal conditions\n- Termination clause (30-60 day notice)\n- IP ownership of co-created assets\n- Performance minimums (if applicable)\n\n### 6. Co-Marketing Playbook\n\n**Joint activities by effort level:**\n\n| Effort | Activity | Expected reach |\n|--------|----------|---------------|\n| Low | Guest blog post swap | 2-5k views each |\n| Low | Social media cross-promotion | 1-3k impressions |\n| Medium | Joint webinar | 200-500 registrants |\n| Medium | Co-branded ebook/report | 500-2k downloads |\n| High | Integration launch campaign | 5-20k impressions |\n| High | Joint conference booth | 500-2k conversations |\n\n### 7. Tracking & Reporting\n\n**Monthly BD dashboard:**\n- Pipeline value by stage\n- Conversion rate stage-to-stage\n- Average deal cycle length\n- Revenue from partnerships (direct + influenced)\n- Partner satisfaction score (quarterly NPS)\n\n**Per-partner tracking:**\n- Leads referred (both directions)\n- Revenue generated\n- Integration usage (if applicable)\n- Support tickets from partner customers\n- Co-marketing campaign performance"
    },
    {
      "name": "cold-outreach",
      "description": "Cold email and LinkedIn outreach. Personalization frameworks, follow-up sequences, deliverability, and reply rate optimization.",
      "category": "growth",
      "features": [
        "Cold email copy frameworks (AIDA, PAS, QVC)",
        "LinkedIn connection and InMail templates",
        "Follow-up sequence timing and cadence",
        "Deliverability optimization (SPF, DKIM, warmup)",
        "Personalization at scale patterns",
        "A/B testing for outreach campaigns"
      ],
      "useCases": [
        "Write a 5-touch cold email sequence",
        "Optimize email deliverability for a new domain",
        "Build LinkedIn outreach for B2B lead gen",
        "Personalize outreach using prospect data"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Cold Outreach\n\n## Workflow\n\n### 1. Deliverability Setup\n\nDo this BEFORE sending a single email. Skipping this = spam folder.\n\n**DNS records (required):**\n```\n# SPF \u2014 authorize your sending IPs\nv=spf1 include:_spf.google.com include:sendgrid.net ~all\n\n# DKIM \u2014 sign emails cryptographically\nselector._domainkey.example.com \u2192 provided by your ESP\n\n# DMARC \u2014 tell receivers what to do with failures\n_dmarc.example.com \u2192 v=DMARC1; p=quarantine; rua=mailto:dmarc@example.com\n```\n\n**Domain warmup schedule (new domain):**\n\n| Week | Emails/day | Target |\n|------|-----------|--------|\n| 1 | 5-10 | Known contacts, internal, friends |\n| 2 | 15-25 | Warm leads, existing network |\n| 3 | 30-50 | Mix of warm and cold |\n| 4 | 50-80 | Full cold outreach |\n| 5+ | 80-100 | Steady state |\n\n**Never send from your primary domain.** Use a dedicated subdomain (e.g., `outreach.example.com`) to protect your main domain reputation.\n\n### 2. Copy Frameworks\n\n**PAS (Problem-Agitate-Solve):**\n```\nSubject: [Problem they have]\n\nHi [Name],\n\n[Problem]: Most [their role] at [their company type] struggle with [specific problem].\n\n[Agitate]: This usually means [consequence] \u2014 which costs [quantified impact].\n\n[Solve]: We help [similar companies] [specific outcome] by [method].\n\n[CTA]: Worth a 15-min call this week?\n```\n\n**QVC (Question-Value-CTA):**\n```\nSubject: Quick question about [their specific situation]\n\nHi [Name],\n\n[Question]: How are you handling [specific challenge] at [Company]?\n\n[Value]: We helped [similar company] [specific result with numbers]\nby [brief method].\n\n[CTA]: Open to hearing how?\n```\n\n**BAB (Before-After-Bridge):**\n```\nSubject: [Desired outcome] for [Company]\n\nHi [Name],\n\n[Before]: Right now [their situation/pain].\n\n[After]: Imagine [desired state with specific metrics].\n\n[Bridge]: That's what we did for [reference customer].\n15 minutes to show you how?\n```\n\n### 3. Follow-Up Sequence\n\n**Timing (7-touch, 21 days):**\n\n| Touch | Day | Type | Purpose |\n|-------|-----|------|---------|\n| 1 | 0 | Email | Initial value prop |\n| 2 | 2 | Email | Different angle or case study |\n| 3 | 5 | LinkedIn | Connect + comment on their content |\n| 4 | 7 | Email | Social proof / testimonial |\n| 5 | 11 | Email | New insight or resource |\n| 6 | 15 | Email | Direct ask with urgency |\n| 7 | 21 | Email | Breakup \u2014 polite close |\n\n**Follow-up rules:**\n- Each touch adds NEW value \u2014 never \"just bumping this up\"\n- Vary the angle: problem, social proof, insight, resource, direct ask\n- Keep emails under 100 words (mobile-first)\n- One CTA per email, always a question\n\n### 4. Personalization\n\n**Tiers by effort:**\n\n| Tier | Time/email | Method | Reply rate |\n|------|-----------|--------|-----------|\n| Generic | 0 min | Template only | 1-3% |\n| Light | 2 min | Company name + role-specific pain | 5-8% |\n| Medium | 5 min | Reference their content/news + custom opener | 10-15% |\n| Deep | 15 min | Unique insight about their business + custom value prop | 20-30% |\n\n**Personalization signals (research checklist):**\n- Recent LinkedIn posts or articles they wrote\n- Company news (funding, hiring, product launch)\n- Tech stack (BuiltWith, Wappalyzer)\n- Job postings (reveal priorities and pain points)\n- Mutual connections\n- Conference appearances or podcast episodes\n\n### 5. Benchmarks\n\n| Metric | Poor | Average | Good | Excellent |\n|--------|------|---------|------|-----------|\n| Open rate | < 30% | 40-50% | 50-65% | > 65% |\n| Reply rate | < 2% | 3-5% | 5-10% | > 10% |\n| Positive reply rate | < 1% | 1-3% | 3-5% | > 5% |\n| Bounce rate | > 5% | 2-5% | 1-2% | < 1% |\n| Unsubscribe rate | > 2% | 1-2% | 0.5-1% | < 0.5% |\n\n**If open rate is low:** Subject line problem. A/B test subjects.\n**If open rate is high but reply is low:** Copy problem. Test different frameworks.\n**If bounce rate is high:** List quality problem. Verify emails before sending.\n\n### 6. A/B Testing\n\n**Test one variable at a time:**\n\n| Variable | Test method |\n|----------|------------|\n| Subject line | Split list 50/50, send simultaneously |\n| Opening line | Same subject, different first sentence |\n| CTA type | Question vs statement vs calendar link |\n| Sending time | Same copy, different send times |\n| Sequence length | 5-touch vs 7-touch |\n| Personalization tier | Light vs medium on same segment |\n\n**Minimum sample:** 100 emails per variant for meaningful results.\n**Run time:** 7-14 days to account for follow-up replies.\n\n### 7. Tools Stack\n\n| Function | Tools |\n|----------|-------|\n| Email finding | Apollo, Hunter.io, Snov.io |\n| Verification | NeverBounce, ZeroBounce, MillionVerifier |\n| Sequencing | Instantly, Lemlist, Smartlead, Apollo |\n| Warmup | Instantly (built-in), Warmbox, Mailwarm |\n| LinkedIn | PhantomBuster, Expandi, Dripify |\n| CRM | HubSpot, Pipedrive, Close |\n\n## Daily Operations Checklist\n\n- [ ] Check reply inbox \u2014 respond within 2 hours during business hours\n- [ ] Review bounce notifications \u2014 remove invalid addresses\n- [ ] Monitor sending reputation (Google Postmaster Tools)\n- [ ] Review sequence analytics \u2014 pause underperforming campaigns\n- [ ] Move positive replies to CRM \u2014 tag source campaign"
    },
    {
      "name": "accounting-finance",
      "description": "Financial modeling, bookkeeping automation, invoicing workflows, tax compliance checklists, and P&L analysis for SMEs and startups.",
      "category": "operations",
      "features": [
        "P&L statement analysis and generation",
        "Cash flow forecasting models",
        "Invoice automation workflows",
        "Tax compliance checklists by jurisdiction",
        "Revenue recognition patterns",
        "Budget vs actual variance analysis"
      ],
      "useCases": [
        "Build a monthly P&L analysis template",
        "Set up automated invoicing workflows",
        "Create a cash flow forecast model",
        "Design a tax compliance checklist for EU SMEs"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Accounting & Finance\n\n## Workflow\n\n### 1. P&L Structure\n\n| Line item | Calculation | Watch for |\n|-----------|-------------|-----------|\n| Revenue | MRR \u00d7 months + one-time | Revenue recognition timing |\n| COGS | Hosting + support + onboarding | Should be < 30% of revenue for SaaS |\n| Gross margin | Revenue - COGS | Target: 70-80% for SaaS |\n| Operating expenses | Sales + Marketing + R&D + G&A | Break down by department |\n| EBITDA | Gross margin - OpEx | Profitability indicator |\n| Net income | EBITDA - interest - taxes - depreciation | Bottom line |\n\n**Monthly P&L review checklist:**\n- [ ] Revenue matches billing system (reconcile \u00b11%)\n- [ ] COGS categorized correctly (not mixed with OpEx)\n- [ ] Headcount costs allocated to correct department\n- [ ] One-time costs flagged and excluded from run-rate\n- [ ] MoM and YoY comparison included\n\n### 2. Cash Flow Forecasting\n\n**13-week rolling forecast (the standard):**\n\n```\nWeek | Starting cash | + Revenue collected | - Payroll | - Vendors | - Tax | = Ending cash\n1    | 150,000       | 45,000              | 30,000   | 8,000    | 0     | 157,000\n2    | 157,000       | 12,000              | 0        | 5,000    | 0     | 164,000\n...\n```\n\n**Key rules:**\n- Use cash collected, not revenue recognized\n- Payroll on actual pay dates (biweekly or monthly)\n- Include tax payments on due dates\n- Flag weeks where ending cash < 2 months of burn\n- Update weekly \u2014 stale forecasts are useless\n\n**Burn rate calculation:**\n```\nMonthly burn = Total cash spent in month (excluding one-time)\nRunway (months) = Current cash balance / Monthly burn\n```\n\nRunway < 6 months = fundraise or cut costs immediately.\n\n### 3. Unit Economics\n\n| Metric | Formula | SaaS benchmark |\n|--------|---------|----------------|\n| CAC | Total sales & marketing spend / New customers | Varies by segment |\n| LTV | ARPU \u00d7 Gross margin % \u00d7 (1 / Monthly churn rate) | 3-5x CAC minimum |\n| LTV:CAC | LTV / CAC | > 3:1 healthy |\n| Payback period | CAC / (ARPU \u00d7 Gross margin %) | < 12 months |\n| Magic number | Net new ARR / Prior quarter S&M spend | > 0.75 = efficient |\n\n### 4. Invoice Automation\n\n**Invoice workflow:**\n1. Contract signed \u2192 create invoice record\n2. Invoice generated \u2192 send on billing date\n3. Payment due \u2192 track aging (net 30/60)\n4. Overdue \u2192 automated reminder sequence:\n   - Day 1 past due: friendly reminder\n   - Day 7: second notice with payment link\n   - Day 14: escalation to account manager\n   - Day 30: final notice, flag for collections\n\n**Invoice must include:**\n- Unique invoice number (sequential)\n- Your company legal name, address, VAT number\n- Client company name, address, VAT number\n- Line items with descriptions, quantities, unit prices\n- Subtotal, tax rate, tax amount, total\n- Payment terms and bank details\n- Issue date and due date\n\n### 5. EU VAT Compliance\n\n| Scenario | VAT treatment |\n|----------|---------------|\n| B2B within same EU country | Charge local VAT |\n| B2B cross-border EU | Reverse charge (0% VAT, buyer reports) |\n| B2C within EU | Charge destination country VAT rate (OSS) |\n| B2C outside EU | No EU VAT |\n| B2B outside EU | No VAT (export) |\n\n**OSS (One-Stop Shop)** \u2014 register in one EU country, report all EU B2C sales there.\n\n**VAT rates (major markets):**\n\n| Country | Standard rate |\n|---------|-------------|\n| Luxembourg | 17% |\n| France | 20% |\n| Germany | 19% |\n| Netherlands | 21% |\n| Spain | 21% |\n| Italy | 22% |\n| Ireland | 23% |\n\n### 6. Revenue Recognition (ASC 606 / IFRS 15)\n\n**5-step model:**\n1. Identify the contract\n2. Identify performance obligations\n3. Determine transaction price\n4. Allocate price to obligations\n5. Recognize revenue when obligation is satisfied\n\n**SaaS specifics:**\n- Monthly subscription: recognize monthly as service delivered\n- Annual prepayment: recognize 1/12 each month (rest is deferred revenue)\n- Setup fees: defer and recognize over contract term (usually)\n- Usage-based: recognize as usage occurs\n\n### 7. Budget vs Actual\n\n**Variance analysis template:**\n\n| Category | Budget | Actual | Variance | % Var | Flag |\n|----------|--------|--------|----------|-------|------|\n| Revenue | 100,000 | 95,000 | -5,000 | -5% | Review |\n| COGS | 25,000 | 23,000 | +2,000 | -8% | OK |\n| Marketing | 30,000 | 38,000 | -8,000 | +27% | Alert |\n| R&D | 40,000 | 41,000 | -1,000 | +3% | OK |\n\n**Rules:**\n- Flag variances > 10% for review\n- Flag variances > 20% for immediate action\n- Always explain WHY, not just WHAT\n- Reforecast quarterly based on actuals"
    },
    {
      "name": "data-analytics",
      "description": "Data analysis workflows, SQL query patterns, dashboard design, KPI frameworks, and data storytelling for business intelligence.",
      "category": "analytics",
      "features": [
        "SQL query patterns for common analyses",
        "Dashboard design principles and layouts",
        "KPI framework selection (OKR, HEART, AARRR)",
        "Cohort analysis and retention curves",
        "A/B test statistical analysis",
        "Data storytelling and visualization best practices"
      ],
      "useCases": [
        "Build a retention cohort analysis from raw data",
        "Design a KPI dashboard for a SaaS product",
        "Write SQL queries for funnel analysis",
        "Create a data-driven board presentation"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Data Analytics\n\n## Workflow\n\n### 1. Define the Question\n\nBefore writing any query, articulate:\n- **What decision** will this analysis inform?\n- **What metric** answers the question?\n- **What timeframe** is relevant?\n- **What segments** matter?\n\nBad: \"How are we doing?\" \u2192 Good: \"What's our 30-day retention rate by acquisition channel for Q1 cohorts?\"\n\n### 2. KPI Framework Selection\n\n| Framework | Best for | Core metrics |\n|-----------|----------|-------------|\n| AARRR (Pirate) | Growth-stage SaaS | Acquisition, Activation, Retention, Revenue, Referral |\n| HEART | Product/UX teams | Happiness, Engagement, Adoption, Retention, Task success |\n| NSM (North Star) | Company alignment | One metric that captures core value delivery |\n| OKR | Goal tracking | Objectives + measurable Key Results |\n\n**Choose NSM first, then AARRR for operational metrics, HEART for product teams.**\n\n### 3. SQL Patterns\n\n**Funnel analysis:**\n```sql\nWITH funnel AS (\n  SELECT\n    user_id,\n    MAX(CASE WHEN event = 'signup' THEN 1 ELSE 0 END) AS signed_up,\n    MAX(CASE WHEN event = 'onboarding_complete' THEN 1 ELSE 0 END) AS onboarded,\n    MAX(CASE WHEN event = 'first_value_action' THEN 1 ELSE 0 END) AS activated,\n    MAX(CASE WHEN event = 'purchase' THEN 1 ELSE 0 END) AS converted\n  FROM events\n  WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'\n  GROUP BY user_id\n)\nSELECT\n  COUNT(*) AS total_users,\n  SUM(signed_up) AS signups,\n  SUM(onboarded) AS onboarded,\n  SUM(activated) AS activated,\n  SUM(converted) AS converted,\n  ROUND(100.0 * SUM(onboarded) / NULLIF(SUM(signed_up), 0), 1) AS signup_to_onboard_pct,\n  ROUND(100.0 * SUM(activated) / NULLIF(SUM(onboarded), 0), 1) AS onboard_to_activate_pct,\n  ROUND(100.0 * SUM(converted) / NULLIF(SUM(activated), 0), 1) AS activate_to_convert_pct\nFROM funnel;\n```\n\n**Cohort retention:**\n```sql\nWITH cohort AS (\n  SELECT\n    user_id,\n    DATE_TRUNC('week', MIN(created_at)) AS cohort_week\n  FROM events\n  WHERE event = 'signup'\n  GROUP BY user_id\n),\nactivity AS (\n  SELECT\n    user_id,\n    DATE_TRUNC('week', created_at) AS activity_week\n  FROM events\n  WHERE event = 'session_start'\n)\nSELECT\n  c.cohort_week,\n  COUNT(DISTINCT c.user_id) AS cohort_size,\n  COUNT(DISTINCT CASE WHEN a.activity_week = c.cohort_week + INTERVAL '1 week' THEN c.user_id END) AS week_1,\n  COUNT(DISTINCT CASE WHEN a.activity_week = c.cohort_week + INTERVAL '2 weeks' THEN c.user_id END) AS week_2,\n  COUNT(DISTINCT CASE WHEN a.activity_week = c.cohort_week + INTERVAL '4 weeks' THEN c.user_id END) AS week_4,\n  COUNT(DISTINCT CASE WHEN a.activity_week = c.cohort_week + INTERVAL '8 weeks' THEN c.user_id END) AS week_8\nFROM cohort c\nLEFT JOIN activity a ON c.user_id = a.user_id\nGROUP BY c.cohort_week\nORDER BY c.cohort_week;\n```\n\n**LTV calculation:**\n```sql\nWITH monthly_revenue AS (\n  SELECT\n    user_id,\n    DATE_TRUNC('month', payment_date) AS month,\n    SUM(amount) AS mrr\n  FROM payments\n  WHERE status = 'succeeded'\n  GROUP BY user_id, DATE_TRUNC('month', payment_date)\n),\nuser_ltv AS (\n  SELECT\n    user_id,\n    SUM(mrr) AS total_revenue,\n    COUNT(DISTINCT month) AS months_active,\n    MIN(month) AS first_payment,\n    MAX(month) AS last_payment\n  FROM monthly_revenue\n  GROUP BY user_id\n)\nSELECT\n  ROUND(AVG(total_revenue), 2) AS avg_ltv,\n  ROUND(AVG(months_active), 1) AS avg_lifetime_months,\n  ROUND(AVG(total_revenue / NULLIF(months_active, 0)), 2) AS avg_arpu\nFROM user_ltv;\n```\n\n**Churn detection:**\n```sql\nSELECT\n  user_id,\n  MAX(created_at) AS last_active,\n  CURRENT_DATE - MAX(created_at)::date AS days_since_active,\n  CASE\n    WHEN CURRENT_DATE - MAX(created_at)::date > 30 THEN 'churned'\n    WHEN CURRENT_DATE - MAX(created_at)::date > 14 THEN 'at_risk'\n    ELSE 'active'\n  END AS status\nFROM events\nWHERE event = 'session_start'\nGROUP BY user_id\nORDER BY days_since_active DESC;\n```\n\n### 4. Dashboard Design\n\n**Layout rules:**\n- Top row: 3-4 KPI cards (current value + trend arrow + % change)\n- Second row: Primary chart (line/area for trends, bar for comparisons)\n- Third row: Breakdown tables or secondary charts\n- Filters: Date range, segment, channel \u2014 always at top\n\n**Chart selection:**\n| Data type | Chart |\n|-----------|-------|\n| Trend over time | Line chart |\n| Part of whole | Stacked bar or donut |\n| Comparison across categories | Horizontal bar |\n| Distribution | Histogram |\n| Correlation | Scatter plot |\n| Funnel stages | Funnel chart |\n| Geographic | Choropleth map |\n\n### 5. Statistical Analysis\n\n**A/B test significance:**\n```python\nfrom scipy import stats\n\ncontrol_conversions, control_total = 120, 1000\nvariant_conversions, variant_total = 145, 1000\n\n# Two-proportion z-test\np1 = control_conversions / control_total\np2 = variant_conversions / variant_total\np_pool = (control_conversions + variant_conversions) / (control_total + variant_total)\nse = (p_pool * (1 - p_pool) * (1/control_total + 1/variant_total)) ** 0.5\nz_score = (p2 - p1) / se\np_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n\nprint(f\"Lift: {((p2/p1) - 1) * 100:.1f}%\")\nprint(f\"p-value: {p_value:.4f}\")\nprint(f\"Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n```\n\n**Sample size calculation:**\n```python\nfrom scipy.stats import norm\n\ndef sample_size(baseline_rate, mde, alpha=0.05, power=0.8):\n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    p1 = baseline_rate\n    p2 = baseline_rate * (1 + mde)\n    n = ((z_alpha * (2*p1*(1-p1))**0.5 + z_beta * (p1*(1-p1) + p2*(1-p2))**0.5) / (p2 - p1)) ** 2\n    return int(n) + 1\n\n# Example: 5% baseline, detect 10% relative lift\nprint(f\"Need {sample_size(0.05, 0.10)} users per variant\")\n```\n\n### 6. Data Storytelling\n\n**Structure every analysis as:**\n1. **Context** \u2014 Why are we looking at this? (1 sentence)\n2. **Finding** \u2014 What did we discover? (lead with the insight, not the method)\n3. **Evidence** \u2014 Show the chart/table that proves it\n4. **Implication** \u2014 So what? What should we do?\n5. **Recommendation** \u2014 Specific next action with expected impact\n\n**Rules:**\n- One insight per slide/section\n- Annotate charts (mark events, callout anomalies)\n- Compare to benchmarks or previous periods\n- Quantify impact in dollars or users, not just percentages"
    },
    {
      "name": "data-management",
      "description": "Data governance, pipeline design, ETL workflows, data quality frameworks, and warehouse architecture for growing teams.",
      "category": "analytics",
      "features": [
        "Data pipeline architecture patterns",
        "ETL/ELT workflow design",
        "Data quality scoring and monitoring",
        "Data catalog and documentation standards",
        "GDPR and data privacy compliance",
        "Data warehouse schema design (star, snowflake)"
      ],
      "useCases": [
        "Design a data pipeline for a SaaS product",
        "Implement data quality monitoring rules",
        "Set up a data catalog for a growing team",
        "Build GDPR-compliant data handling workflows"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Data Management\n\n## Workflow\n\n### 1. Pipeline Architecture\n\n**Batch vs streaming:**\n\n| Approach | Latency | Use case | Tools |\n|----------|---------|----------|-------|\n| Batch ETL | Hours | Daily reporting, historical analysis | Airflow, dbt, Fivetran |\n| Micro-batch | Minutes | Near-real-time dashboards | Spark Streaming, dbt + scheduler |\n| Streaming | Seconds | Real-time alerts, live feeds | Kafka, Flink, Kinesis |\n\n**Decision:** Start with batch. Move to streaming only when business requires sub-minute latency.\n\n**Standard pipeline pattern:**\n```\nSources \u2192 Extract \u2192 Landing/Raw \u2192 Transform \u2192 Staging \u2192 Serve \u2192 BI/Analytics\n  \u2193         \u2193          \u2193             \u2193           \u2193        \u2193\n APIs    Fivetran    Raw zone     dbt models   Clean    Looker/\n DBs     Airbyte    (immutable)  (versioned)  tables   Metabase\n Files   Custom     S3/GCS       SQL tests    Views    API\n```\n\n### 2. Warehouse Schema Design\n\n**Star schema (recommended for analytics):**\n```sql\n-- Fact table (events/transactions \u2014 append-only, granular)\nCREATE TABLE fact_orders (\n  order_id BIGINT PRIMARY KEY,\n  customer_key INT REFERENCES dim_customers(customer_key),\n  product_key INT REFERENCES dim_products(product_key),\n  date_key INT REFERENCES dim_dates(date_key),\n  quantity INT,\n  revenue DECIMAL(10,2),\n  discount DECIMAL(10,2),\n  created_at TIMESTAMP\n);\n\n-- Dimension table (descriptive attributes \u2014 slowly changing)\nCREATE TABLE dim_customers (\n  customer_key INT PRIMARY KEY,  -- surrogate key\n  customer_id VARCHAR(50),        -- natural key\n  name VARCHAR(200),\n  email VARCHAR(200),\n  segment VARCHAR(50),\n  country VARCHAR(50),\n  created_at TIMESTAMP,\n  updated_at TIMESTAMP,\n  is_current BOOLEAN DEFAULT TRUE  -- SCD Type 2\n);\n\n-- Date dimension (pre-populated)\nCREATE TABLE dim_dates (\n  date_key INT PRIMARY KEY,       -- YYYYMMDD format\n  full_date DATE,\n  year INT,\n  quarter INT,\n  month INT,\n  week INT,\n  day_of_week VARCHAR(10),\n  is_weekend BOOLEAN,\n  is_holiday BOOLEAN\n);\n```\n\n**Star vs snowflake:**\n- Star: denormalized dimensions, faster queries, easier to understand. **Use this.**\n- Snowflake: normalized dimensions, saves storage, more joins. Only if storage is a concern (rarely).\n\n### 3. dbt Project Structure\n\n```\nmodels/\n  staging/          -- 1:1 with source tables, rename/cast/clean\n    stg_stripe_payments.sql\n    stg_hubspot_contacts.sql\n  intermediate/     -- business logic joins\n    int_customer_orders.sql\n  marts/            -- final tables for BI\n    dim_customers.sql\n    fact_orders.sql\n    metrics_monthly_revenue.sql\n  schema.yml        -- tests and documentation\n```\n\n**dbt model example:**\n```sql\n-- models/marts/dim_customers.sql\nWITH customers AS (\n  SELECT * FROM {{ ref('stg_hubspot_contacts') }}\n),\norders AS (\n  SELECT customer_id, MIN(order_date) AS first_order, COUNT(*) AS total_orders, SUM(revenue) AS ltv\n  FROM {{ ref('stg_stripe_payments') }}\n  GROUP BY customer_id\n)\nSELECT\n  c.customer_id,\n  c.name,\n  c.email,\n  c.segment,\n  c.country,\n  o.first_order,\n  o.total_orders,\n  o.ltv,\n  CASE WHEN o.ltv > 1000 THEN 'high' WHEN o.ltv > 100 THEN 'medium' ELSE 'low' END AS value_tier\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\n```\n\n### 4. Data Quality Framework\n\n**Quality dimensions:**\n\n| Dimension | Definition | Check |\n|-----------|-----------|-------|\n| Completeness | No missing required values | `WHERE column IS NULL` count |\n| Accuracy | Values are correct | Spot-check against source, range validation |\n| Consistency | Same value across systems | Compare CRM vs billing vs product DB |\n| Timeliness | Data is fresh enough | `MAX(updated_at)` vs expected freshness |\n| Uniqueness | No unintended duplicates | `COUNT(*) vs COUNT(DISTINCT key)` |\n| Validity | Values match expected format | Regex, enum validation, range checks |\n\n**dbt tests (add to schema.yml):**\n```yaml\nmodels:\n  - name: dim_customers\n    columns:\n      - name: customer_id\n        tests:\n          - not_null\n          - unique\n      - name: email\n        tests:\n          - not_null\n          - accepted_values:\n              values: []\n              quote: false\n              config:\n                where: \"email NOT LIKE '%@%'\"\n                severity: warn\n      - name: segment\n        tests:\n          - accepted_values:\n              values: ['enterprise', 'mid-market', 'smb', 'self-serve']\n```\n\n**Data quality score:**\n```\nQuality score = (Completeness \u00d7 0.3) + (Accuracy \u00d7 0.25) + (Consistency \u00d7 0.2) + (Timeliness \u00d7 0.15) + (Uniqueness \u00d7 0.1)\n```\nTarget: > 95% across all dimensions.\n\n### 5. GDPR Compliance\n\n**Data subject rights checklist:**\n\n| Right | Implementation |\n|-------|---------------|\n| Access (Art. 15) | Export all personal data within 30 days |\n| Rectification (Art. 16) | Allow users to correct their data |\n| Erasure (Art. 17) | Delete personal data on request (right to be forgotten) |\n| Portability (Art. 20) | Provide data in machine-readable format |\n| Restriction (Art. 18) | Stop processing but retain data |\n| Objection (Art. 21) | Opt out of marketing/profiling |\n\n**Data retention policy template:**\n\n| Data type | Retention period | Basis |\n|-----------|-----------------|-------|\n| Account data | Duration of contract + 3 years | Contractual necessity |\n| Payment records | 7 years | Legal obligation (tax) |\n| Analytics events | 26 months | Legitimate interest |\n| Marketing consent | Until withdrawn | Consent |\n| Support tickets | 3 years after resolution | Legitimate interest |\n| Deleted account data | 30 days (grace period) then purge | Erasure right |\n\n**Consent management:**\n- Record: what, when, how, and version of consent text\n- Allow granular consent (analytics, marketing, third-party separately)\n- Make withdrawal as easy as giving consent\n- Re-consent on material changes to privacy policy\n\n### 6. Monitoring\n\n**Automated alerts:**\n- Pipeline failure (any step) \u2192 Slack/PagerDuty immediate\n- Data freshness > expected SLA \u2192 warn after 1 hour, alert after 4 hours\n- Quality score drops below 90% \u2192 alert data team\n- Duplicate rate > 1% \u2192 alert\n- Schema change detected in source \u2192 alert (breaking changes)"
    },
    {
      "name": "google-analytics",
      "description": "GA4 setup, event taxonomy, custom dimensions, conversion tracking, audience segments, and reporting automation.",
      "category": "analytics",
      "features": [
        "GA4 property setup and configuration",
        "Event taxonomy design and naming conventions",
        "Custom dimensions and metrics",
        "Conversion tracking implementation",
        "Audience segment creation and analysis",
        "Looker Studio reporting automation",
        "Cross-domain tracking setup"
      ],
      "useCases": [
        "Set up GA4 with a structured event taxonomy",
        "Implement e-commerce tracking in GA4",
        "Build automated Looker Studio reports",
        "Create audience segments for remarketing"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Google Analytics 4\n\n## Workflow\n\n### 1. Measurement Plan\n\nBefore touching GA4, define what matters:\n\n| Layer | Question | Example |\n|-------|----------|---------|\n| Business objective | What's the goal? | Increase trial signups 20% |\n| KPI | How do we measure? | Trial signup rate, activation rate |\n| Events | What do we track? | `sign_up`, `tutorial_complete`, `plan_selected` |\n| Dimensions | What context? | plan_type, referral_source, user_role |\n\n### 2. Event Taxonomy\n\nUse a consistent naming convention. Never use spaces or capitals in event names.\n\n**Naming pattern:** `object_action` (noun_verb)\n\n```\n# Core events (auto-collected \u2014 don't recreate)\npage_view, session_start, first_visit, user_engagement\n\n# Recommended events (use GA4 standard names)\nsign_up, login, purchase, add_to_cart, begin_checkout\n\n# Custom events (your business logic)\ntrial_started\nfeature_activated\nplan_upgraded\ninvite_sent\nonboarding_completed\nsupport_ticket_opened\n```\n\n**Implementation (gtag.js):**\n```javascript\n// Custom event with parameters\ngtag('event', 'trial_started', {\n  plan_type: 'pro',\n  referral_source: 'pricing_page',\n  value: 49\n});\n\n// User property (set once per user)\ngtag('set', 'user_properties', {\n  account_type: 'enterprise',\n  company_size: '50-200'\n});\n```\n\n**GTM dataLayer push:**\n```javascript\ndataLayer.push({\n  event: 'plan_upgraded',\n  plan_from: 'free',\n  plan_to: 'pro',\n  mrr_delta: 49\n});\n```\n\n### 3. Custom Dimensions & Metrics\n\nRegister in GA4 Admin \u2192 Custom definitions before sending data.\n\n| Scope | Dimension | Example values | Use |\n|-------|-----------|----------------|-----|\n| Event | plan_type | free, pro, enterprise | Segment by plan |\n| Event | feature_name | dashboard, export, api | Feature adoption |\n| User | account_type | individual, team, enterprise | User segmentation |\n| User | signup_source | organic, paid, referral | Acquisition quality |\n\n### 4. Conversion Tracking\n\nMark key events as conversions in GA4 Admin \u2192 Events \u2192 toggle \"Mark as conversion.\"\n\n**High-value conversions:**\n- `sign_up` \u2014 new account created\n- `purchase` \u2014 payment completed\n- `trial_started` \u2014 trial activated\n- `plan_upgraded` \u2014 expansion revenue\n\n**Micro-conversions (track but don't optimize ads against):**\n- `onboarding_completed`\n- `feature_activated`\n- `invite_sent`\n\n### 5. Audience Segments\n\nBuild in GA4 \u2192 Audiences for remarketing and analysis:\n\n| Audience | Condition | Use |\n|----------|-----------|-----|\n| Active trial users | `trial_started` in last 14 days AND `session_count > 3` | Nurture campaigns |\n| Power users | `feature_activated` count > 10 in 30 days | Upsell targeting |\n| Churned users | `last_active > 30 days` AND `account_type = paid` | Win-back campaigns |\n| High-intent visitors | Viewed pricing page 2+ times, no signup | Retargeting ads |\n\n### 6. Cross-Domain Tracking\n\nFor multi-domain setups (app.example.com + www.example.com):\n\n```javascript\ngtag('config', 'G-XXXXXXX', {\n  linker: {\n    domains: ['example.com', 'app.example.com', 'checkout.example.com']\n  }\n});\n```\n\nVerify in GA4 DebugView \u2014 sessions should NOT restart across domains.\n\n### 7. Attribution Settings\n\nGA4 Admin \u2192 Attribution settings:\n\n- **Reporting attribution model:** Data-driven (default, recommended)\n- **Lookback window:** 30 days for acquisition, 90 days for other conversions\n- **Cross-channel:** Enable for accurate multi-touch attribution\n\n### 8. Looker Studio Reporting\n\nConnect GA4 as data source. Key dashboard pages:\n\n**Overview dashboard:**\n- Sessions, users, new users (line chart, 30d trend)\n- Conversion rate by channel (bar chart)\n- Top landing pages by sessions and conversion rate (table)\n- Device category breakdown (pie chart)\n\n**Acquisition dashboard:**\n- Users by source/medium (table with sparklines)\n- Campaign performance (sessions, conversions, CPA)\n- Organic vs paid trend (combo chart)\n\n**Engagement dashboard:**\n- Events per session by page (heatmap)\n- Feature adoption funnel (custom funnel chart)\n- User retention cohort (built-in cohort table)\n\n### 9. Debugging\n\n**GA4 DebugView:** Enable with:\n```javascript\ngtag('config', 'G-XXXXXXX', { debug_mode: true });\n```\nOr install GA Debugger Chrome extension.\n\n**Common issues:**\n- Events not showing \u2192 check real-time report (24-48h processing delay for standard reports)\n- Duplicate events \u2192 check for double gtag installation (GTM + hardcoded)\n- Missing conversions \u2192 verify event is marked as conversion AND firing correctly\n- Cross-domain breaks \u2192 check linker config and excluded referrals\n\n### 10. GA4 Data API\n\nQuery data programmatically:\n```python\nfrom google.analytics.data_v1beta import BetaAnalyticsDataClient\nfrom google.analytics.data_v1beta.types import RunReportRequest, DateRange, Dimension, Metric\n\nclient = BetaAnalyticsDataClient()\nrequest = RunReportRequest(\n    property=f\"properties/{PROPERTY_ID}\",\n    date_ranges=[DateRange(start_date=\"30daysAgo\", end_date=\"today\")],\n    dimensions=[Dimension(name=\"sessionSource\"), Dimension(name=\"sessionMedium\")],\n    metrics=[Metric(name=\"sessions\"), Metric(name=\"conversions\")],\n)\nresponse = client.run_report(request)\nfor row in response.rows:\n    print(row.dimension_values[0].value, row.metric_values[0].value)\n```\n\n## Weekly Audit Checklist\n\n- [ ] Check real-time for expected event flow\n- [ ] Verify conversion counts match backend data (\u00b15% tolerance)\n- [ ] Review (not set) and (other) values in reports \u2014 indicates taxonomy gaps\n- [ ] Check data freshness in Looker Studio dashboards\n- [ ] Review audience sizes for remarketing \u2014 flag if dropping unexpectedly\n- [ ] Audit new events in DebugView before production rollout"
    },
    {
      "name": "search-console",
      "description": "Google Search Console optimization. Index coverage, performance analysis, sitemap management, and search appearance debugging.",
      "category": "analytics",
      "features": [
        "Index coverage audit and fix workflows",
        "Performance report analysis (CTR, position, impressions)",
        "Sitemap submission and monitoring",
        "Core Web Vitals debugging",
        "Rich results and structured data validation",
        "URL inspection and indexing requests",
        "Search appearance optimization"
      ],
      "useCases": [
        "Audit and fix index coverage issues",
        "Analyze search performance trends by page cluster",
        "Debug rich results and structured data errors",
        "Optimize CTR using search appearance data"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Google Search Console\n\n## Workflow\n\n### 1. Property Setup\n\nVerify ownership via DNS TXT record (most reliable):\n```\ngoogle-site-verification=XXXXXXXXXXXXXXXX\n```\nAlternatives: HTML file upload, HTML meta tag, Google Analytics, Google Tag Manager.\n\n**Add both versions:**\n- `https://example.com` (URL prefix) \u2014 for specific path filtering\n- `example.com` (Domain) \u2014 for comprehensive data including subdomains\n\n### 2. Index Coverage Audit\n\nNavigate to Pages \u2192 Indexing to review status:\n\n| Status | Meaning | Action |\n|--------|---------|--------|\n| Valid | Indexed, no issues | Monitor |\n| Valid with warnings | Indexed but has issues | Fix warnings |\n| Excluded | Not indexed (intentional or not) | Review each reason |\n| Error | Cannot index, wants to | Fix immediately |\n\n**Common exclusion reasons and fixes:**\n\n| Reason | Fix |\n|--------|-----|\n| Crawled - currently not indexed | Improve content quality, add internal links |\n| Discovered - currently not indexed | Submit in sitemap, build backlinks, wait |\n| Excluded by noindex tag | Remove noindex if page should be indexed |\n| Alternate page with proper canonical | Expected for canonical dedup \u2014 verify canonical is correct |\n| Blocked by robots.txt | Update robots.txt if page should be crawled |\n| Duplicate without user-selected canonical | Set explicit canonical tag |\n| Soft 404 | Add real content or return proper 404 status |\n\n### 3. Performance Analysis\n\nKey metrics: impressions, clicks, CTR, average position.\n\n**Analysis by query cluster:**\n1. Export performance data (Queries tab, 16 months max)\n2. Group queries by intent/topic\n3. Calculate cluster-level CTR vs expected CTR for position:\n\n| Position | Expected CTR |\n|----------|-------------|\n| 1 | 25-35% |\n| 2 | 12-18% |\n| 3 | 8-12% |\n| 4-5 | 5-8% |\n| 6-10 | 2-5% |\n\n**If actual CTR < expected:** Title/description needs optimization.\n**If actual CTR > expected:** Strong snippet \u2014 protect this content.\n\n**Quick wins \u2014 filter for:**\n- Position 5-15 with high impressions \u2192 optimize to push into top 5\n- High impressions, low CTR \u2192 rewrite title tags and meta descriptions\n- Position 1-3, declining impressions \u2192 content freshness issue\n\n### 4. Sitemap Management\n\nSubmit at Sitemaps \u2192 Add a new sitemap:\n```\nhttps://example.com/sitemap.xml\n```\n\n**Sitemap audit checklist:**\n- [ ] All indexable pages included\n- [ ] No noindex/canonicalized pages in sitemap\n- [ ] `<lastmod>` dates are accurate (not auto-generated today's date)\n- [ ] Response is HTTP 200 with valid XML\n- [ ] Under 50,000 URLs per sitemap (use sitemap index for larger sites)\n- [ ] Submitted in GSC AND referenced in robots.txt\n\n### 5. Core Web Vitals\n\nCheck Page Experience \u2192 Core Web Vitals:\n\n| Metric | Good | Needs Improvement | Poor |\n|--------|------|-------------------|------|\n| LCP (Largest Contentful Paint) | \u2264 2.5s | \u2264 4.0s | > 4.0s |\n| INP (Interaction to Next Paint) | \u2264 200ms | \u2264 500ms | > 500ms |\n| CLS (Cumulative Layout Shift) | \u2264 0.1 | \u2264 0.25 | > 0.25 |\n\n**Debugging workflow:**\n1. Identify failing URL groups in GSC\n2. Test specific URLs with PageSpeed Insights\n3. Fix the highest-impact issue first (usually LCP)\n4. Validate fix in GSC (takes 28 days for field data)\n\n**Common fixes:**\n- LCP: Optimize hero image (WebP, proper sizing, preload), eliminate render-blocking resources\n- INP: Reduce JavaScript execution time, break long tasks, use `requestIdleCallback`\n- CLS: Set explicit width/height on images/video, avoid dynamic content injection above the fold\n\n### 6. URL Inspection\n\nUse URL Inspection tool to:\n- Check if a specific URL is indexed\n- See how Googlebot renders the page\n- Request indexing for new/updated pages\n- Debug canonical selection issues\n\n**API access for bulk inspection:**\n```python\nfrom googleapiclient.discovery import build\nservice = build('searchconsole', 'v1', credentials=creds)\nrequest = {\n    'inspectionUrl': 'https://example.com/page',\n    'siteUrl': 'https://example.com'\n}\nresponse = service.urlInspection().index().inspect(body=request).execute()\nprint(response['inspectionResult']['indexStatusResult']['coverageState'])\n```\n\n### 7. Rich Results Validation\n\nCheck Enhancements section for structured data issues:\n- FAQ, How-to, Product, Review, Breadcrumb, Article, Event, LocalBusiness\n\n**Validation workflow:**\n1. Test with Rich Results Test (search.google.com/test/rich-results)\n2. Fix schema errors shown in GSC\n3. Validate fix \u2014 GSC will re-crawl and update status\n\n**Common schema errors:**\n- Missing required fields (e.g., `aggregateRating` without `reviewCount`)\n- Invalid date formats (use ISO 8601: `2025-01-15`)\n- Mismatched canonical and structured data URLs\n\n### 8. Search Appearance Optimization\n\n**Title tag formula:** `Primary Keyword \u2014 Benefit | Brand` (under 60 chars)\n**Meta description:** Include primary keyword, CTA, value prop (under 155 chars)\n\n**Test changes:**\n1. Identify pages with CTR below position-expected benchmarks\n2. Rewrite title + description\n3. Track CTR change over 2-4 weeks in GSC\n\n## Weekly Audit Checklist\n\n- [ ] Check index coverage for new errors\n- [ ] Review performance trends (7d vs previous 7d)\n- [ ] Monitor Core Web Vitals for regressions\n- [ ] Check sitemap processing status\n- [ ] Review manual actions (should always be empty)\n- [ ] Check security issues\n- [ ] Flag pages losing >20% impressions week-over-week"
    },
    {
      "name": "bing-webmaster",
      "description": "Bing Webmaster Tools setup, IndexNow protocol, URL submission, backlink analysis, and Bing-specific SEO optimization.",
      "category": "analytics",
      "features": [
        "Bing Webmaster Tools setup and verification",
        "IndexNow protocol implementation",
        "URL submission and crawl control",
        "Backlink profile analysis",
        "Bing-specific ranking factor optimization",
        "SEO reports and diagnostics"
      ],
      "useCases": [
        "Set up Bing Webmaster Tools for a new site",
        "Implement IndexNow for instant indexing",
        "Analyze and compare Bing vs Google rankings",
        "Optimize content for Bing search algorithm"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Bing Webmaster Tools\n\n## Workflow\n\n### 1. Setup & Verification\n\n**Verification methods (pick one):**\n- XML file upload (BingSiteAuth.xml to root)\n- Meta tag (`<meta name=\"msvalidate.01\" content=\"XXXX\" />`)\n- CNAME DNS record\n- Auto-verify if already in Google Search Console (import)\n\n**Import from GSC:** Bing offers one-click import of all your GSC properties \u2014 fastest path.\n\n### 2. IndexNow Implementation\n\nIndexNow tells search engines about URL changes instantly. Supported by Bing, Yandex, and others.\n\n**Simple implementation (single URL):**\n```bash\n# Generate API key (any UUID works)\nKEY=\"your-api-key-here\"\n\n# Place key file at site root\necho \"$KEY\" > public/$KEY.txt\n# Accessible at: https://example.com/$KEY.txt\n\n# Notify Bing of URL change\ncurl \"https://api.indexnow.org/indexnow?url=https://example.com/updated-page&key=$KEY\"\n```\n\n**Batch submission (up to 10,000 URLs):**\n```bash\ncurl -X POST \"https://api.indexnow.org/indexnow\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"host\": \"example.com\",\n    \"key\": \"your-api-key\",\n    \"keyLocation\": \"https://example.com/your-api-key.txt\",\n    \"urlList\": [\n      \"https://example.com/page1\",\n      \"https://example.com/page2\",\n      \"https://example.com/page3\"\n    ]\n  }'\n```\n\n**Automate with build/deploy hook:**\n```javascript\n// Next.js post-build script\nconst changedUrls = getChangedPages(); // your logic\nif (changedUrls.length > 0) {\n  await fetch('https://api.indexnow.org/indexnow', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      host: 'example.com',\n      key: process.env.INDEXNOW_KEY,\n      keyLocation: `https://example.com/${process.env.INDEXNOW_KEY}.txt`,\n      urlList: changedUrls\n    })\n  });\n}\n```\n\n### 3. Bing vs Google \u2014 Key Differences\n\n| Factor | Google | Bing |\n|--------|--------|------|\n| Social signals | Minimal impact | Significant ranking factor |\n| Exact match domains | Discounted | Still somewhat rewarded |\n| Multimedia content | Moderate impact | Higher weight (images, video) |\n| Page authority | Links-heavy | More balanced (links + social + content) |\n| Flash/Silverlight | Not indexed | Historically indexed (legacy) |\n| Keyword in URL | Minor factor | More weight |\n| Official site badge | No equivalent | Verified site badge available |\n\n### 4. URL Submission API\n\n**For new or updated content (beyond IndexNow):**\n```bash\ncurl -X POST \"https://ssl.bing.com/webmaster/api.svc/json/SubmitUrl?apikey=$BING_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"siteUrl\":\"https://example.com\",\"url\":\"https://example.com/new-page\"}'\n```\n\n**Daily quota:** 10,000 URLs/day for verified sites. Use for bulk submissions after migrations.\n\n### 5. Backlink Analysis\n\nBing Webmaster provides free backlink data (competitive with paid tools for basics):\n- Inbound links report: domains linking to you\n- Anchor text distribution\n- Top linked pages\n- New and lost links\n\n**Audit checklist:**\n- [ ] Disavow toxic backlinks (spam, irrelevant foreign domains)\n- [ ] Check anchor text diversity (too many exact-match = risky)\n- [ ] Monitor new links weekly for negative SEO\n- [ ] Compare backlink profile vs top 3 competitors\n\n### 6. Bing SEO Optimization\n\n**Content optimization:**\n- Use exact-match keywords in H1 and first paragraph (Bing is more literal than Google)\n- Include multimedia: images with descriptive alt text, embedded video\n- Ensure fast page load (Bing uses page speed as a ranking factor)\n- Add schema markup (Bing uses it for rich results and entity understanding)\n\n**Technical optimization:**\n- Submit XML sitemap in Bing Webmaster Tools\n- Enable IndexNow for real-time indexing\n- Set crawl control settings (Bing respects crawl-delay in robots.txt)\n- Use hreflang for international pages (Bing supports it)\n\n### 7. Reporting\n\n**Monthly Bing audit:**\n- [ ] Check crawl errors and fix\n- [ ] Review search performance (impressions, clicks, CTR)\n- [ ] Compare Bing vs Google rankings for top 20 keywords\n- [ ] Monitor IndexNow submission success rate\n- [ ] Review and update sitemap if site structure changed\n- [ ] Check for manual penalties (rare but check)"
    },
    {
      "name": "yandex-webmaster",
      "description": "Yandex Webmaster setup, Yandex-specific SEO, regional targeting, Turbo pages, and Russian market search optimization.",
      "category": "analytics",
      "features": [
        "Yandex Webmaster verification and setup",
        "Regional targeting configuration",
        "Turbo pages implementation",
        "Yandex-specific meta tags and directives",
        "Content quality assessment (ICS rating)",
        "Russian market keyword research"
      ],
      "useCases": [
        "Set up Yandex Webmaster for a Russian market launch",
        "Implement Turbo pages for mobile speed",
        "Configure regional targeting for multi-city businesses",
        "Optimize content for Yandex ranking factors"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Yandex Webmaster\n\n## Workflow\n\n### 1. Setup & Verification\n\n**Verification methods:**\n- HTML file upload\n- Meta tag: `<meta name=\"yandex-verification\" content=\"XXXX\" />`\n- DNS TXT record\n- WHOIS email verification\n\n**Post-verification:**\n- Submit sitemap: Settings \u2192 Sitemap files \u2192 Add\n- Set main mirror: Settings \u2192 Site indexing \u2192 Main mirror (www vs non-www)\n- Configure regional targeting: Settings \u2192 Regional targeting \u2192 Select regions\n\n### 2. Yandex vs Google \u2014 Ranking Differences\n\n| Factor | Google | Yandex |\n|--------|--------|--------|\n| Backlinks | Primary signal | Important but less dominant |\n| Text relevance | Semantic, context-based | More literal keyword matching |\n| Commercial factors | Implicit | Explicit ranking factors (prices, contact info, delivery) |\n| User behavior | Moderate signal | Heavy signal (CTR, dwell time, pogo-sticking) |\n| Regional targeting | IP + hreflang | Explicit geo-assignment per page |\n| Content freshness | Important for news | Important across all content types |\n| Site quality (ICS) | No direct equivalent | Explicit quality rating visible in Webmaster |\n\n### 3. Commercial Ranking Factors\n\nYandex explicitly values these for commercial queries:\n\n| Factor | Implementation |\n|--------|---------------|\n| Contact information | Full address, phone, email on every page (or footer) |\n| Prices visible | Show prices on product/service pages |\n| Delivery information | Clear delivery terms and costs |\n| Company details | Legal entity name, registration numbers |\n| Reviews/ratings | Customer reviews on site |\n| Wide assortment | More products/services = stronger signal |\n| Secure payment | SSL + payment security badges |\n\n### 4. Regional Targeting\n\nYandex assigns pages to specific regions. Critical for local businesses.\n\n**Set region in Yandex Webmaster:** Settings \u2192 Regional targeting \u2192 Assign region per site section.\n\n**For multi-region businesses:**\n- Create separate regional landing pages (/moscow/, /spb/, /novosibirsk/)\n- Each page should have region-specific content (not just city name swapped)\n- Register in Yandex Business Directory for each location\n- Add structured local data (address, phone per region)\n\n### 5. Turbo Pages\n\nTurbo pages are Yandex's AMP equivalent \u2014 ultra-fast mobile pages served from Yandex cache.\n\n**RSS feed implementation:**\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<rss xmlns:yandex=\"http://news.yandex.ru\" xmlns:media=\"http://search.yahoo.com/mrss/\"\n     xmlns:turbo=\"http://turbo.yandex.ru\" version=\"2.0\">\n  <channel>\n    <title>Site Name</title>\n    <link>https://example.com</link>\n    <turbo:analytics type=\"Yandex\" id=\"XXXXXXXX\"/>\n\n    <item turbo=\"true\">\n      <title>Article Title</title>\n      <link>https://example.com/article</link>\n      <turbo:content>\n        <![CDATA[\n          <header>\n            <h1>Article Title</h1>\n            <figure>\n              <img src=\"https://example.com/image.jpg\"/>\n            </figure>\n          </header>\n          <p>Article content goes here. Use standard HTML.</p>\n          <h2>Subheading</h2>\n          <p>More content with <a href=\"https://example.com\">links</a>.</p>\n        ]]>\n      </turbo:content>\n    </item>\n  </channel>\n</rss>\n```\n\n**Submit:** Turbo pages \u2192 Sources \u2192 Add RSS feed URL.\n\n**Turbo page benefits:**\n- 15x faster load time on mobile\n- Higher position in mobile search results\n- Yandex serves from their CDN (zero server load)\n- Supports ads, analytics, forms, e-commerce widgets\n\n### 6. ICS Quality Rating\n\nICS (Index of Citation for Sites) is Yandex's visible site quality score (0-10,000+).\n\n**Factors that improve ICS:**\n- Regular content updates\n- User engagement metrics (low bounce, high dwell time)\n- Backlink quality (Yandex values editorial links from relevant sites)\n- Site age and history\n- Presence in Yandex Business Directory\n- Social signals (shares, mentions)\n\n**Check ICS:** Yandex Webmaster \u2192 Site quality \u2192 ICS rating.\n\n### 7. Yandex-Specific Meta Tags\n\n```html\n<!-- Verification -->\n<meta name=\"yandex-verification\" content=\"XXXX\" />\n\n<!-- Control indexing -->\n<meta name=\"robots\" content=\"index, follow\" />\n<meta name=\"yandex\" content=\"noyaca\" />  <!-- Don't replace description with Yandex Catalog -->\n\n<!-- Original source (for syndicated content) -->\n<meta property=\"article:source\" content=\"https://original-source.com/article\" />\n```\n\n### 8. Yandex Webmaster API\n\n```python\nimport requests\n\nheaders = {\"Authorization\": f\"OAuth {YANDEX_OAUTH_TOKEN}\"}\nhost_id = \"https:example.com:443\"\n\n# Get search queries\nr = requests.get(\n    f\"https://api.webmaster.yandex.net/v4/user/{USER_ID}/hosts/{host_id}/search-queries/popular\",\n    headers=headers,\n    params={\"date_from\": \"2025-01-01\", \"date_to\": \"2025-01-31\"}\n)\nfor query in r.json().get(\"queries\", []):\n    print(query[\"query_text\"], query[\"indicators\"][\"TOTAL_SHOWS\"], query[\"indicators\"][\"TOTAL_CLICKS\"])\n```\n\n## Monthly Audit Checklist\n\n- [ ] Check indexing status \u2014 pages indexed vs submitted\n- [ ] Review ICS rating trend\n- [ ] Analyze top queries and position changes\n- [ ] Check Turbo page errors (if using)\n- [ ] Verify regional targeting is correct\n- [ ] Review crawl errors and excluded pages\n- [ ] Compare Yandex vs Google performance for key queries\n- [ ] Update sitemap if site structure changed"
    },
    {
      "name": "social-media-growth",
      "description": "Platform-specific growth tactics. Algorithmic optimization, engagement hacking, viral mechanics, and community building at scale.",
      "category": "growth",
      "features": [
        "Platform algorithm analysis (LinkedIn, Twitter/X, Instagram, TikTok)",
        "Engagement rate optimization tactics",
        "Viral content mechanics and hooks",
        "Community building playbooks",
        "Hashtag and trending topic strategies",
        "Cross-platform content distribution",
        "Influencer outreach and collaboration"
      ],
      "useCases": [
        "Grow a LinkedIn following from 0 to 10k",
        "Optimize content for the Twitter/X algorithm",
        "Build a community-led growth strategy",
        "Create a viral content playbook for TikTok"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Social Media Growth\n\n## Platform Algorithms\n\n### LinkedIn\n\n**What the algorithm rewards:**\n- Dwell time (people stop scrolling to read)\n- Comments (especially long, thoughtful ones)\n- Shares to DMs (private distribution)\n- Early engagement (first 60 minutes critical)\n\n**Content format performance:**\n\n| Format | Avg. reach | Best for |\n|--------|-----------|----------|\n| Text-only (story) | High | Personal stories, lessons |\n| Carousel (PDF) | Very high | Frameworks, how-tos |\n| Poll | High | Engagement, market research |\n| Video (native) | Medium | Thought leadership |\n| Article | Low | SEO, evergreen content |\n| Image + text | Medium | Quick insights |\n\n**Posting rules:**\n- 3-5 posts per week (more = diminishing returns)\n- Best times: Tue-Thu 8-10am target timezone\n- Hook in first 2 lines (before \"see more\" fold)\n- End with a question (drives comments)\n- No external links in post body (kills reach) \u2014 put links in first comment\n- Engage with 10-15 posts before and after publishing yours\n\n### Twitter/X\n\n**What the algorithm rewards:**\n- Replies and quote tweets (conversation)\n- Bookmark rate (save for later = high quality signal)\n- Time spent on tweet (long-form, threads)\n- Profile clicks from tweet\n\n| Format | Best for |\n|--------|----------|\n| Thread (5-12 tweets) | Deep dives, storytelling |\n| Single tweet + image | Quick insights, hot takes |\n| Quote tweet with take | Building on others' ideas |\n| Poll | Engagement, opinions |\n\n**Growth tactics:**\n- Reply to large accounts in your niche (first 30 min of their post)\n- Build a \"reply network\" \u2014 20-30 accounts you consistently engage with\n- Post threads at 8am or 12pm target timezone\n- Pin your best-performing thread\n- Use 1-2 hashtags max (more looks spammy)\n\n### Instagram\n\n**Algorithm priority (2025):**\n- Reels > Carousels > Static images > Stories for reach\n- Saves and shares weighted higher than likes\n- Watch time on Reels (completion rate)\n\n| Content type | Cadence | Purpose |\n|-------------|---------|---------|\n| Reels | 3-5/week | Reach and discovery |\n| Carousels | 2-3/week | Education, saves |\n| Stories | Daily | Engagement, polls |\n| Static | 1-2/week | Brand aesthetic |\n\n**Reel optimization:**\n- Hook in first 1.5 seconds\n- 15-30 seconds optimal length\n- Add text overlays (many watch muted)\n- Use trending audio (check Reels tab)\n- End with a loop (seamless replay = more watch time)\n\n### TikTok\n\n**Algorithm is pure content quality \u2014 followers barely matter for reach.**\n\n- First 500 views = test group. Performance there determines viral push.\n- Watch time is king (especially rewatch rate)\n- Comment velocity in first hour\n- Share rate to external (DMs, other platforms)\n\n**Format rules:**\n- 15-45 seconds for max completion rate\n- Hook in first 1 second (pattern interrupt)\n- Native look (not polished ads) outperforms production quality\n- Reply to comments with video (TikTok boosts these)\n- Post 1-3 times daily for growth phase\n\n## Viral Content Mechanics\n\n**Hook types that stop the scroll:**\n\n| Hook type | Example |\n|-----------|---------|\n| Contrarian | \"Stop posting on LinkedIn at 8am\" |\n| Curiosity gap | \"This one change doubled our signups\" |\n| List/number | \"5 tools I use daily that nobody talks about\" |\n| Story | \"I got fired. Best thing that happened.\" |\n| Challenge | \"Most founders can't answer this question\" |\n\n**Viral loop anatomy:**\n1. **Hook** \u2014 stop the scroll (1-2 seconds)\n2. **Setup** \u2014 create anticipation (why should I care?)\n3. **Payload** \u2014 deliver the value (insight, story, framework)\n4. **CTA** \u2014 drive action (follow, save, share, comment)\n\n## Content Calendar\n\n**Weekly template (B2B SaaS):**\n\n| Day | LinkedIn | Twitter/X | Instagram |\n|-----|---------|-----------|-----------|\n| Mon | Industry insight | Thread | Reel |\n| Tue | Personal story | Hot take + image | Carousel |\n| Wed | How-to carousel | Engage (no post) | Stories only |\n| Thu | Poll or question | Thread | Reel |\n| Fri | Behind-the-scenes | Casual/funny tweet | Static + story |\n\n## Community Building\n\n**Engagement-first strategy (first 90 days):**\n1. Identify 50 accounts in your niche (mix of sizes)\n2. Engage genuinely on their content daily (comment, not just like)\n3. DM 5 new people weekly with specific value (not pitch)\n4. Create content that references/amplifies community members\n5. Host a weekly space/live/room on one topic\n\n**Community flywheel:** Engage others \u2192 They engage you \u2192 Algorithm sees engagement \u2192 More reach \u2192 More community members \u2192 Repeat\n\n## Growth Metrics\n\n| Metric | Track | Benchmark |\n|--------|-------|-----------|\n| Follower growth rate | Weekly | 2-5% week-over-week in growth phase |\n| Engagement rate | Per post | LinkedIn: 3-5%, Twitter: 1-3%, Instagram: 3-6% |\n| Impressions | Weekly | 10x follower count = good |\n| Profile visits | Weekly | 5-10% of impressions |\n| Link clicks | Per post | 1-3% of impressions |\n| Saves/bookmarks | Per post | 2-5% of engagement = high-quality content |"
    },
    {
      "name": "crm-operations",
      "description": "CRM setup, pipeline automation, lead routing, deal tracking, and operational workflows for HubSpot, Salesforce, Pipedrive.",
      "category": "operations",
      "features": [
        "CRM property and field architecture",
        "Pipeline stage design and automation",
        "Lead scoring and routing rules",
        "Deal tracking and revenue forecasting",
        "Email sequence integration",
        "Reporting dashboard configuration",
        "Data hygiene and deduplication workflows"
      ],
      "useCases": [
        "Design a sales pipeline in HubSpot from scratch",
        "Set up automated lead routing rules",
        "Build revenue forecasting dashboards",
        "Create data cleanup workflows for CRM hygiene"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# CRM Operations\n\n## Workflow\n\n### 1. Property Architecture\n\n**Core contact properties:**\n\n| Property | Type | Purpose |\n|----------|------|---------|\n| lifecycle_stage | Dropdown | Subscriber \u2192 Lead \u2192 MQL \u2192 SQL \u2192 Opportunity \u2192 Customer |\n| lead_source | Dropdown | How they found you (organic, paid, referral, outbound) |\n| lead_score | Number | Calculated engagement + fit score |\n| assigned_owner | User | Current owner for routing |\n| last_engaged | Date | Last meaningful interaction |\n| icp_fit | Dropdown | Strong, moderate, weak |\n\n**Core company properties:**\n\n| Property | Type | Purpose |\n|----------|------|---------|\n| industry | Dropdown | Vertical classification |\n| employee_count | Number | Size segmentation |\n| arr_potential | Currency | Estimated deal value |\n| tech_stack | Multi-select | Integration opportunities |\n| decision_stage | Dropdown | Awareness, consideration, decision |\n\n**Naming convention:** `snake_case`, prefix custom properties with category (e.g., `billing_`, `product_`, `marketing_`).\n\n### 2. Pipeline Design\n\n**SaaS sales pipeline:**\n\n| Stage | Definition | Exit criteria | Win probability |\n|-------|-----------|---------------|----------------|\n| New | Lead qualified, first meeting booked | Discovery call completed | 10% |\n| Discovery | Pain and fit confirmed | Champion identified, budget discussed | 20% |\n| Demo | Product demonstrated | Technical validation passed | 40% |\n| Proposal | Pricing/terms shared | Verbal agreement on terms | 60% |\n| Negotiation | Contract in legal review | Redlines resolved | 80% |\n| Closed Won | Contract signed | Payment received or PO issued | 100% |\n| Closed Lost | Deal dead | Loss reason documented | 0% |\n\n**Required fields per stage transition:**\n- New \u2192 Discovery: `pain_point`, `budget_range`, `timeline`\n- Discovery \u2192 Demo: `champion_name`, `decision_maker`, `competitor`\n- Demo \u2192 Proposal: `technical_validated = true`\n- Proposal \u2192 Negotiation: `proposal_sent_date`, `contract_value`\n- Any \u2192 Closed Lost: `loss_reason` (required, dropdown)\n\n### 3. Lead Scoring\n\n**Two-axis scoring: Fit (demographic) + Engagement (behavioral)**\n\n**Fit scoring (0-50 points):**\n\n| Signal | Points | Rationale |\n|--------|--------|-----------|\n| ICP industry match | +15 | Right vertical |\n| Company size 50-500 | +10 | Sweet spot segment |\n| Decision-maker title | +10 | VP+ or C-level |\n| Target geography | +5 | In serviceable market |\n| Uses complementary tools | +5 | Integration potential |\n| Company size < 10 | -10 | Below minimum viable |\n| Student/personal email | -15 | Not a buyer |\n\n**Engagement scoring (0-50 points, decays 50% per 30 days inactive):**\n\n| Action | Points | Decay |\n|--------|--------|-------|\n| Visited pricing page | +10 | Yes |\n| Requested demo | +15 | No |\n| Downloaded content | +5 | Yes |\n| Attended webinar | +8 | Yes |\n| Opened 3+ emails in 7 days | +5 | Yes |\n| Replied to email | +10 | No |\n| Visited 5+ pages in session | +5 | Yes |\n\n**Thresholds:**\n- Score \u2265 70: MQL \u2192 auto-route to sales\n- Score 40-69: Nurture sequence\n- Score < 40: Marketing automation only\n\n### 4. Lead Routing\n\n**Round-robin with rules:**\n```\nIF lead_score >= 70 AND arr_potential >= $50k:\n  \u2192 Route to enterprise AE (named accounts)\nELIF lead_score >= 70 AND arr_potential < $50k:\n  \u2192 Route to SMB AE (round-robin)\nELIF lead_score 40-69:\n  \u2192 Route to SDR for qualification\nELSE:\n  \u2192 Nurture automation\n```\n\n**SLA:** New MQL must be contacted within 5 minutes (speed to lead matters). If not claimed in 15 minutes, re-route.\n\n### 5. Deal Forecasting\n\n**Weighted pipeline method:**\n```\nForecast = \u03a3 (Deal value \u00d7 Stage probability \u00d7 Rep confidence adjustment)\n```\n\n| Forecast category | Definition |\n|-------------------|-----------|\n| Committed | 90%+ probability, verbal/written commitment |\n| Best case | 50-89% probability, active engagement |\n| Pipeline | 10-49% probability, early stage |\n| Upside | Identified but not yet in pipeline |\n\n**Monthly forecast review:** Compare forecast vs actual for last 3 months to calibrate rep-level accuracy.\n\n### 6. Data Hygiene\n\n**Weekly automated cleanup:**\n- Merge duplicate contacts (match on email \u2192 company + name)\n- Flag contacts with no activity > 90 days\n- Validate email addresses quarterly (bounce rate > 5% = problem)\n- Standardize company names (remove Inc, LLC, Ltd variants)\n- Archive closed-lost deals > 12 months old\n\n**Data quality dashboard:**\n- % contacts with complete required fields\n- % deals with next step date in future\n- Duplicate contact rate\n- Bounce rate on email sends\n- % contacts with valid lifecycle stage\n\n### 7. Automation Workflows\n\n**Essential automations:**\n\n| Trigger | Action |\n|---------|--------|\n| Form submission | Create contact, set lifecycle stage, enroll in sequence |\n| Lead score crosses MQL threshold | Notify owner, create task, update lifecycle |\n| Deal stage change | Update contact lifecycle, trigger next email |\n| No activity 14 days on open deal | Alert owner, create follow-up task |\n| Closed Won | Trigger onboarding sequence, notify CS team |\n| Closed Lost | Enroll in re-engagement nurture (90 day delay) |"
    },
    {
      "name": "competitor-intelligence",
      "description": "Competitive analysis frameworks, market positioning, feature comparison matrices, and win/loss analysis for strategic planning.",
      "category": "growth",
      "features": [
        "Competitor identification and mapping",
        "Feature comparison matrix generation",
        "Pricing intelligence and benchmarking",
        "Win/loss analysis frameworks",
        "Market positioning maps",
        "Competitive content gap analysis"
      ],
      "useCases": [
        "Build a competitive landscape analysis",
        "Create a feature comparison matrix for sales enablement",
        "Analyze competitor pricing strategies",
        "Run a win/loss analysis on recent deals"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Competitor Intelligence\n\n## Workflow\n\n### 1. Competitor Identification\n\n**Three tiers:**\n\n| Tier | Definition | Track |\n|------|-----------|-------|\n| Direct | Same product, same market | Deep: pricing, features, messaging, every move |\n| Adjacent | Different product, same buyer | Monitor: major launches, positioning changes |\n| Aspirational | Where you want to be in 2-3 years | Quarterly: strategy, positioning, market moves |\n\n**Discovery methods:**\n- Search your top 5 keywords \u2014 who ranks?\n- Ask churned customers who they switched to\n- Check G2/Capterra/TrustRadius category pages\n- Monitor \"alternatives to [your product]\" searches\n- Track who bids on your brand keywords\n\n### 2. Feature Comparison Matrix\n\n| Feature | You | Competitor A | Competitor B | Competitor C |\n|---------|-----|-------------|-------------|-------------|\n| Core feature 1 | Full | Full | Partial | None |\n| Core feature 2 | Full | None | Full | Full |\n| Integration X | Full | Partial | None | Full |\n| API access | All plans | Enterprise only | Pro+ | None |\n| SSO/SAML | Pro+ | Enterprise only | All plans | Enterprise only |\n| Support SLA | 4h (Pro) | 24h | 8h | 12h |\n| Pricing (entry) | $49/mo | $79/mo | $39/mo | $99/mo |\n| Free tier | Yes | No | Yes (limited) | No |\n\n**Rules:**\n- Be honest. Don't mark competitors as \"None\" when they have partial support.\n- Update quarterly minimum \u2014 features change fast.\n- Note which plan includes each feature (not just \"has it\").\n- Source every claim (link to their docs/pricing page).\n\n### 3. Positioning Map\n\n**2x2 matrix \u2014 choose two axes that matter to your buyers:**\n\nCommon axis pairs:\n- Ease of use \u2194 Feature depth\n- SMB focus \u2194 Enterprise focus\n- Price \u2194 Capability\n- Self-serve \u2194 High-touch\n- Horizontal \u2194 Vertical/specialized\n\n**How to place competitors:**\n1. Score each competitor 1-10 on both axes\n2. Use customer reviews, demos, and published materials (not assumptions)\n3. Identify the white space \u2014 where are there no competitors?\n4. Position yourself in or near the white space (if it has demand)\n\n### 4. Win/Loss Analysis\n\n**Interview framework (20-min call with recent wins AND losses):**\n\n| Question | Purpose |\n|----------|---------|\n| What triggered the search for a solution? | Understand buying trigger |\n| What alternatives did you evaluate? | Competitive set |\n| What were your top 3 criteria? | Decision factors |\n| Why did you choose [winner] / not choose us? | Win/loss reason |\n| What almost changed your mind? | Close call factors |\n| How was the buying experience? | Process feedback |\n\n**Aggregate analysis (quarterly, minimum 20 interviews):**\n- Win rate by competitor: Who do we beat most? Lose to most?\n- Top 3 win reasons: What keeps winning deals for us?\n- Top 3 loss reasons: What keeps losing them?\n- Feature gaps cited: What do prospects wish we had?\n- Pricing feedback: Are we perceived as expensive, fair, cheap?\n\n### 5. Sales Battlecards\n\n**Template (one per competitor):**\n\n```markdown\n# Battlecard: [Competitor Name]\n\n## Quick Facts\n- Founded: [year] | HQ: [city] | Employees: ~[X] | Funding: $[X]M\n- Pricing: [starting price] - [enterprise price]\n- Target: [who they sell to]\n\n## They Say (their positioning)\n\"[Their tagline/main claim]\"\n\n## We Say (our counter-positioning)\n\"[How we differentiate \u2014 one sentence]\"\n\n## When We Win\n- [Scenario 1: specific situation where we're stronger]\n- [Scenario 2]\n- [Scenario 3]\n\n## When We Lose\n- [Scenario 1: specific situation where they're stronger]\n- [Scenario 2]\n\n## Landmines (questions to ask prospects to highlight our strengths)\n- \"How do they handle [area where competitor is weak]?\"\n- \"What happens when you need [feature they lack]?\"\n- \"Have you looked into their [known pain point \u2014 pricing, support, etc.]?\"\n\n## Objection Handling\n| Their claim | Our response |\n|-------------|-------------|\n| \"[Competitor claim 1]\" | \"[Factual counter with proof]\" |\n| \"[Competitor claim 2]\" | \"[Factual counter with proof]\" |\n\n## Proof Points\n- [Customer who switched from them to us + result]\n- [Head-to-head benchmark or comparison data]\n- [Review quote from G2/Capterra]\n```\n\n### 6. Monitoring\n\n**Ongoing competitive intelligence:**\n\n| Source | Frequency | What to track |\n|--------|-----------|--------------|\n| Their website/blog | Weekly | Messaging changes, new features, pricing |\n| G2/Capterra reviews | Monthly | Sentiment trends, new complaints |\n| Job postings | Monthly | Strategic direction (hiring = investing) |\n| Social media | Weekly | Positioning, customer conversations |\n| Press/funding | As it happens | Funding rounds, partnerships, acquisitions |\n| Their product | Quarterly | Sign up for free trial, document UX |\n\n**Competitive newsletter (internal, monthly):**\n- Top 3 competitive moves this month\n- Win/loss trend update\n- New feature comparison updates\n- Pricing or positioning changes\n- Recommended battlecard updates"
    },
    {
      "name": "revenue-operations",
      "description": "RevOps frameworks, funnel metrics, forecasting models, GTM alignment, and operational efficiency for scaling teams.",
      "category": "operations",
      "features": [
        "Revenue funnel metric definitions",
        "Forecasting model design (weighted, linear, AI-assisted)",
        "GTM team alignment frameworks",
        "Quota and territory planning",
        "Tech stack audit and optimization",
        "Handoff process design (marketing to sales to CS)"
      ],
      "useCases": [
        "Design a revenue forecasting model",
        "Align marketing and sales on funnel definitions",
        "Audit and optimize the GTM tech stack",
        "Build handoff processes between teams"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Revenue Operations\n\n## Workflow\n\n### 1. Revenue Funnel Definitions\n\nAlign ALL teams on the same definitions:\n\n| Stage | Definition | Owner | SLA |\n|-------|-----------|-------|-----|\n| Visitor | Hit website or content | Marketing | \u2014 |\n| Lead | Known contact (form fill, signup) | Marketing | Enrich within 24h |\n| MQL | Meets scoring threshold (fit + engagement) | Marketing | Route within 5 min |\n| SAL | Sales accepted, meeting booked | SDR/BDR | Contact within 1 hour |\n| SQL | Qualified by sales (BANT/MEDDIC confirmed) | AE | Discovery within 3 days |\n| Opportunity | In pipeline with defined next steps | AE | Advance or close within 90 days |\n| Closed Won | Contract signed, revenue booked | AE \u2192 CS | Handoff within 48h |\n\n**Conversion benchmarks (B2B SaaS):**\n\n| Stage transition | Benchmark |\n|-----------------|-----------|\n| Visitor \u2192 Lead | 2-5% |\n| Lead \u2192 MQL | 15-30% |\n| MQL \u2192 SAL | 60-80% |\n| SAL \u2192 SQL | 40-60% |\n| SQL \u2192 Opportunity | 50-70% |\n| Opportunity \u2192 Closed Won | 20-30% |\n\n### 2. Forecasting Models\n\n**Weighted pipeline (standard):**\n```\nDeal forecast = Deal value \u00d7 Stage probability\nTotal forecast = \u03a3 all deal forecasts\n```\n\n**Historical conversion (more accurate):**\n```\nExpected revenue = Current stage count \u00d7 Historical stage-to-close rate \u00d7 Average deal size\n```\n\n**Bottoms-up (most accurate, most work):**\n```\nRep forecast = Committed + (Best case \u00d7 0.5) + (Pipeline \u00d7 0.15)\nTeam forecast = \u03a3 rep forecasts \u00d7 Historical accuracy multiplier\n```\n\n**Forecast accuracy tracking:**\n\n| Month | Forecast | Actual | Accuracy |\n|-------|----------|--------|----------|\n| Jan | $250k | $230k | 92% |\n| Feb | $280k | $310k | 90% |\n| Mar | $300k | $275k | 92% |\n\nTarget: \u00b110% accuracy consistently. If not: reps are sandbagging or being optimistic.\n\n### 3. GTM Alignment\n\n**Weekly GTM standup (30 min):**\n- Marketing: pipeline contribution this week, upcoming campaigns\n- Sales: deal updates, blockers, competitive intel\n- CS: churn risks, expansion opportunities, product feedback\n- RevOps: funnel health, forecast update, process issues\n\n**Monthly revenue review (60 min):**\n- Funnel conversion rates vs targets\n- Pipeline coverage (3x target = healthy)\n- Win rate trends by segment, source, rep\n- Churn and expansion ARR\n- Forecast vs actual analysis\n\n### 4. Quota & Territory Planning\n\n**Quota setting formula:**\n```\nCompany target = Board-approved ARR target\nSales capacity = # ramped AEs \u00d7 quota per AE\nQuota per AE = Company target / # ramped AEs \u00d7 1.15 (buffer for attrition)\n```\n\n**Territory design principles:**\n- Equal opportunity (similar pipeline potential per territory)\n- Minimize travel (geographic clustering)\n- Account for existing relationships (don't reassign active deals)\n- Review quarterly (territories drift as markets change)\n\n**Ramp schedule:**\n\n| Month | % of full quota | Expectation |\n|-------|----------------|-------------|\n| 1-2 | 0% | Training, shadowing, certification |\n| 3 | 25% | First qualified meetings |\n| 4 | 50% | First deals in pipeline |\n| 5 | 75% | First closed deals |\n| 6+ | 100% | Fully ramped |\n\n### 5. Handoff Processes\n\n**Marketing \u2192 SDR (MQL handoff):**\n```\nTrigger: Lead score \u2265 MQL threshold\nData passed: Lead source, content consumed, pages visited, company info, score breakdown\nSDR action: Research (5 min) \u2192 personalized outreach within 1 hour\nFeedback loop: SDR marks SAL accepted/rejected with reason \u2192 Marketing adjusts scoring\n```\n\n**SDR \u2192 AE (SAL handoff):**\n```\nTrigger: Discovery call completed, BANT confirmed\nData passed: Pain points, budget range, timeline, decision process, competitors\nAE action: Review notes \u2192 demo prep \u2192 schedule demo within 3 days\nHandoff format: Warm intro email (SDR introduces AE + summarizes conversation)\n```\n\n**AE \u2192 CS (Closed Won handoff):**\n```\nTrigger: Contract signed\nData passed: Contract terms, use case, success criteria, stakeholders, technical requirements\nCS action: Onboarding kickoff within 48 hours\nHandoff format: Internal doc + joint call (AE + CS + customer)\n```\n\n### 6. Tech Stack Audit\n\n**Core RevOps stack:**\n\n| Layer | Tool | Purpose |\n|-------|------|---------|\n| CRM | HubSpot / Salesforce | Single source of truth |\n| Engagement | Outreach / Salesloft | Sales sequences |\n| Intelligence | Gong / Chorus | Call recording + analysis |\n| Enrichment | Clearbit / Apollo | Contact and company data |\n| Attribution | HubSpot / Dreamdata | Marketing attribution |\n| BI | Looker / Metabase | Cross-functional dashboards |\n| Communication | Slack + CRM integration | Real-time notifications |\n\n**Audit checklist:**\n- [ ] Data flows bidirectionally between all tools\n- [ ] No manual data entry between systems\n- [ ] Single source of truth for each data type\n- [ ] Reporting pulls from one source (not multiple conflicting dashboards)\n- [ ] Total cost < 15% of ARR (healthy range)\n\n### 7. RevOps Metrics Dashboard\n\n| Metric | Cadence | Target |\n|--------|---------|--------|\n| Pipeline coverage ratio | Weekly | 3-4x quarterly target |\n| Win rate | Monthly | 20-30% |\n| Average sales cycle | Monthly | Track trend, reduce 10% YoY |\n| CAC payback | Monthly | < 12 months |\n| Net revenue retention | Monthly | > 110% |\n| Forecast accuracy | Monthly | \u00b110% |\n| Speed to lead | Real-time | < 5 minutes |\n| Pipeline created per rep | Weekly | Even distribution |"
    },
    {
      "name": "ab-testing",
      "description": "A/B test design, statistical analysis, sample size calculation, experiment prioritization, and results interpretation.",
      "category": "conversion",
      "features": [
        "Hypothesis generation frameworks",
        "Sample size and duration calculators",
        "Statistical significance analysis",
        "Experiment prioritization (ICE, RICE, PIE)",
        "Multi-variant test design",
        "Results interpretation and documentation"
      ],
      "useCases": [
        "Design an A/B test for a pricing page",
        "Calculate required sample size for significance",
        "Prioritize a backlog of experiment ideas",
        "Interpret test results and make ship/no-ship decisions"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# A/B Testing\n\n## Workflow\n\n### 1. Hypothesis Generation\n\n**Format:** If we [change], then [metric] will [improve/decrease] by [amount], because [rationale].\n\n**Example:** If we shorten the signup form from 5 fields to 3, then signup completion rate will increase by 15%, because friction reduction at high-intent moments increases conversion.\n\n### 2. Prioritization\n\n**ICE framework (quick):**\n\n| Factor | Score 1-10 | Definition |\n|--------|-----------|------------|\n| Impact | How much will it move the metric? |\n| Confidence | How sure are we it'll work? |\n| Ease | How fast/cheap to implement? |\n| **ICE Score** | (I + C + E) / 3 |\n\n**RICE framework (more rigorous):**\n\n| Factor | Definition |\n|--------|-----------|\n| Reach | How many users affected per quarter? |\n| Impact | Expected effect size (0.25, 0.5, 1, 2, 3) |\n| Confidence | % sure (100%, 80%, 50%) |\n| Effort | Person-weeks to implement |\n| **RICE Score** | (R \u00d7 I \u00d7 C) / E |\n\n### 3. Sample Size Calculation\n\n**Formula:**\n```\nn = (Z_\u03b1/2 \u00d7 \u221a(2p\u0304(1-p\u0304)) + Z_\u03b2 \u00d7 \u221a(p\u2081(1-p\u2081) + p\u2082(1-p\u2082)))\u00b2 / (p\u2082 - p\u2081)\u00b2\n\nWhere:\n  p\u2081 = baseline conversion rate\n  p\u2082 = expected conversion rate (baseline \u00d7 (1 + MDE))\n  p\u0304  = (p\u2081 + p\u2082) / 2\n  Z_\u03b1/2 = 1.96 (for 95% confidence)\n  Z_\u03b2   = 0.84 (for 80% power)\n```\n\n**Quick reference table:**\n\n| Baseline rate | MDE (relative) | Sample per variant |\n|--------------|----------------|-------------------|\n| 2% | 10% | 78,000 |\n| 2% | 20% | 20,000 |\n| 5% | 10% | 30,000 |\n| 5% | 20% | 7,700 |\n| 10% | 10% | 14,300 |\n| 10% | 20% | 3,700 |\n| 20% | 10% | 6,300 |\n| 20% | 20% | 1,600 |\n\n**Test duration:**\n```\nDays needed = (Sample per variant \u00d7 2) / Daily traffic to test page\n```\n\nMinimum: 7 days (capture day-of-week effects). Maximum: 4 weeks (avoid novelty decay).\n\n### 4. Test Design\n\n**Rules:**\n- One hypothesis per test\n- Randomly assign users, not sessions (avoid flickering)\n- Use the same metric definition for control and variant\n- Define primary metric AND guardrail metrics before launch\n- Don't peek at results before reaching sample size\n\n**Guardrail metrics (always monitor):**\n- Page load time (variant shouldn't be slower)\n- Error rate\n- Revenue per user (don't increase signups but tank revenue)\n- Bounce rate\n\n### 5. Statistical Analysis\n\n**Frequentist approach (standard):**\n\n```python\nimport numpy as np\nfrom scipy import stats\n\n# Results\ncontrol = {'visitors': 5000, 'conversions': 250}  # 5.0%\nvariant = {'visitors': 5000, 'conversions': 295}  # 5.9%\n\np1 = control['conversions'] / control['visitors']\np2 = variant['conversions'] / variant['visitors']\np_pool = (control['conversions'] + variant['conversions']) / (control['visitors'] + variant['visitors'])\n\nse = np.sqrt(p_pool * (1 - p_pool) * (1/control['visitors'] + 1/variant['visitors']))\nz = (p2 - p1) / se\np_value = 2 * (1 - stats.norm.cdf(abs(z)))\n\nlift = (p2 - p1) / p1 * 100\nci_95 = 1.96 * np.sqrt(p1*(1-p1)/control['visitors'] + p2*(1-p2)/variant['visitors'])\n\nprint(f\"Control: {p1:.3%}\")\nprint(f\"Variant: {p2:.3%}\")\nprint(f\"Lift: {lift:.1f}%\")\nprint(f\"95% CI: [{(p2-p1-ci_95)/p1*100:.1f}%, {(p2-p1+ci_95)/p1*100:.1f}%]\")\nprint(f\"p-value: {p_value:.4f}\")\nprint(f\"Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n```\n\n**Bayesian approach (when you want probability of being better):**\n\n```python\nfrom scipy.stats import beta\n\na_alpha = control['conversions'] + 1\na_beta = control['visitors'] - control['conversions'] + 1\nb_alpha = variant['conversions'] + 1\nb_beta = variant['visitors'] - variant['conversions'] + 1\n\n# Monte Carlo simulation\nsamples_a = beta.rvs(a_alpha, a_beta, size=100000)\nsamples_b = beta.rvs(b_alpha, b_beta, size=100000)\n\nprob_b_better = (samples_b > samples_a).mean()\nprint(f\"P(variant > control): {prob_b_better:.1%}\")\n```\n\n### 6. Ship / No-Ship Decision\n\n| Scenario | Decision |\n|----------|----------|\n| p < 0.05 AND lift > MDE AND guardrails OK | Ship |\n| p < 0.05 AND lift > 0 but < MDE | Ship if no cost, otherwise iterate |\n| p > 0.05 AND lift direction positive | Inconclusive \u2014 extend or iterate |\n| p < 0.05 AND lift negative | Kill variant |\n| Guardrail metric degraded | Kill variant regardless of primary metric |\n\n### 7. Documentation Template\n\n```markdown\n## Test: [Name]\n**Hypothesis:** If we [change], then [metric] will [change] by [amount]\n**Primary metric:** [metric name]\n**Guardrails:** [metric 1, metric 2]\n**Sample size:** [X per variant]\n**Duration:** [start] to [end]\n\n### Results\n| Metric | Control | Variant | Lift | p-value | Sig? |\n|--------|---------|---------|------|---------|------|\n| Primary | X% | Y% | +Z% | 0.XX | Y/N |\n\n### Decision: Ship / Kill / Iterate\n**Reasoning:** [Why]\n**Next test:** [What we learned and what to try next]\n```\n\n## Common Mistakes\n\n- Stopping early because results \"look significant\" (peeking inflates false positives)\n- Running too many variants (splits traffic, takes forever to reach significance)\n- Testing tiny changes on low-traffic pages (will never reach significance)\n- Not segmenting results (variant might win overall but lose on mobile)\n- Ignoring practical significance (statistically significant 0.1% lift isn't worth shipping)"
    },
    {
      "name": "retention-analytics",
      "description": "Churn analysis, cohort retention, engagement scoring, health scoring, and win-back strategies for SaaS products.",
      "category": "analytics",
      "features": [
        "Churn prediction modeling",
        "Cohort retention analysis",
        "Customer health scoring",
        "Engagement metric design",
        "Win-back campaign frameworks",
        "NPS and satisfaction tracking"
      ],
      "useCases": [
        "Build a customer health score model",
        "Analyze retention by acquisition cohort",
        "Design a churn prediction early warning system",
        "Create a win-back email campaign for churned users"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Retention Analytics\n\n## Workflow\n\n### 1. Cohort Retention Analysis\n\n**SQL \u2014 weekly retention cohorts:**\n```sql\nWITH cohorts AS (\n  SELECT user_id, DATE_TRUNC('week', created_at) AS cohort\n  FROM users WHERE created_at >= CURRENT_DATE - INTERVAL '90 days'\n),\nactivity AS (\n  SELECT DISTINCT user_id, DATE_TRUNC('week', event_time) AS active_week\n  FROM events WHERE event = 'session_start'\n)\nSELECT\n  c.cohort,\n  COUNT(DISTINCT c.user_id) AS cohort_size,\n  ROUND(100.0 * COUNT(DISTINCT CASE WHEN a.active_week = c.cohort + INTERVAL '1 week' THEN c.user_id END) / COUNT(DISTINCT c.user_id), 1) AS w1_pct,\n  ROUND(100.0 * COUNT(DISTINCT CASE WHEN a.active_week = c.cohort + INTERVAL '2 weeks' THEN c.user_id END) / COUNT(DISTINCT c.user_id), 1) AS w2_pct,\n  ROUND(100.0 * COUNT(DISTINCT CASE WHEN a.active_week = c.cohort + INTERVAL '4 weeks' THEN c.user_id END) / COUNT(DISTINCT c.user_id), 1) AS w4_pct,\n  ROUND(100.0 * COUNT(DISTINCT CASE WHEN a.active_week = c.cohort + INTERVAL '8 weeks' THEN c.user_id END) / COUNT(DISTINCT c.user_id), 1) AS w8_pct\nFROM cohorts c\nLEFT JOIN activity a ON c.user_id = a.user_id\nGROUP BY c.cohort ORDER BY c.cohort;\n```\n\n**Retention benchmarks (B2B SaaS):**\n\n| Timeframe | Good | Great | Best-in-class |\n|-----------|------|-------|---------------|\n| Week 1 | 40% | 55% | 70%+ |\n| Month 1 | 30% | 45% | 60%+ |\n| Month 3 | 20% | 35% | 50%+ |\n| Month 12 | 15% | 25% | 40%+ |\n\n**If W1 retention is below 40%:** Activation problem. Fix onboarding.\n**If W1 is fine but M3 drops:** Value delivery problem. Users aren't finding ongoing value.\n\n### 2. Customer Health Score\n\n**Composite score (0-100):**\n\n| Signal | Weight | Scoring |\n|--------|--------|---------|\n| Product usage frequency | 25% | Daily=100, Weekly=60, Monthly=30, None=0 |\n| Feature breadth | 20% | % of key features used in last 30d |\n| Support tickets | 15% | 0=100, 1-2=70, 3+=30 (inverse) |\n| NPS response | 15% | Promoter=100, Passive=50, Detractor=0 |\n| License utilization | 15% | % of seats/capacity used |\n| Billing health | 10% | Current=100, Late=30, Failed=0 |\n\n**Health tiers:**\n\n| Score | Tier | Action |\n|-------|------|--------|\n| 80-100 | Healthy | Expansion opportunity \u2014 upsell |\n| 60-79 | Neutral | Monitor \u2014 check in monthly |\n| 40-59 | At risk | Proactive outreach \u2014 CS call within 7 days |\n| 0-39 | Critical | Immediate intervention \u2014 executive sponsor call |\n\n### 3. Churn Prediction Signals\n\n**Early warning signals (14-30 days before churn):**\n\n| Signal | Detection | Risk level |\n|--------|-----------|-----------|\n| Login frequency dropped 50%+ | Compare 7d avg vs 30d avg | High |\n| Key feature usage stopped | Zero events on core features | High |\n| Support ticket with negative sentiment | NLP on ticket text | Medium |\n| Admin user inactive > 14 days | Activity tracking | High |\n| Failed payment not resolved in 7 days | Billing system | Critical |\n| Competitor mentioned in support | Keyword detection | Medium |\n| Contract renewal < 60 days + low health | Health score + contract date | High |\n\n**SQL \u2014 at-risk detection:**\n```sql\nSELECT\n  u.user_id,\n  u.company_name,\n  u.plan,\n  u.contract_end,\n  COALESCE(recent.sessions_7d, 0) AS sessions_last_7d,\n  COALESCE(prior.sessions_7d, 0) AS sessions_prior_7d,\n  CASE\n    WHEN COALESCE(recent.sessions_7d, 0) = 0 THEN 'critical'\n    WHEN recent.sessions_7d < prior.sessions_7d * 0.5 THEN 'high_risk'\n    WHEN recent.sessions_7d < prior.sessions_7d * 0.75 THEN 'medium_risk'\n    ELSE 'healthy'\n  END AS risk_level\nFROM users u\nLEFT JOIN (\n  SELECT user_id, COUNT(*) AS sessions_7d\n  FROM events WHERE event = 'session_start' AND event_time >= CURRENT_DATE - 7\n  GROUP BY user_id\n) recent ON u.user_id = recent.user_id\nLEFT JOIN (\n  SELECT user_id, COUNT(*) AS sessions_7d\n  FROM events WHERE event = 'session_start' AND event_time BETWEEN CURRENT_DATE - 14 AND CURRENT_DATE - 7\n  GROUP BY user_id\n) prior ON u.user_id = prior.user_id\nWHERE u.status = 'active'\nORDER BY risk_level DESC, u.contract_end ASC;\n```\n\n### 4. Win-Back Campaigns\n\n**Timing sequence:**\n\n| Day after churn | Channel | Message |\n|----------------|---------|---------|\n| 1 | Email | \"We're sorry to see you go\" + feedback survey |\n| 7 | Email | \"Here's what you're missing\" + new feature highlight |\n| 30 | Email | \"Come back\" + incentive (discount, extended trial, free month) |\n| 60 | Email | Final offer + case study of returning customer |\n| 90 | Email | \"Door's always open\" \u2014 no offer, just warm close |\n\n**Win-back incentive tiers:**\n\n| Customer value | Incentive |\n|---------------|-----------|\n| High LTV (top 20%) | Personal call from CS + custom offer |\n| Medium LTV | 20-30% discount for 3 months |\n| Low LTV | Free month or extended trial |\n| Free plan churn | Feature highlight email only (no discount) |\n\n**Win-back benchmarks:** Expect 5-15% of churned customers to return within 90 days with active win-back. 2-5% without any effort.\n\n### 5. NPS & Satisfaction\n\n**NPS survey timing:**\n- After onboarding (day 14-30)\n- Quarterly for active customers\n- After major interaction (support resolution, feature launch)\n- Never during billing issues or outages\n\n**NPS action framework:**\n\n| Score | Segment | Action |\n|-------|---------|--------|\n| 9-10 | Promoter | Request review/referral, case study candidate |\n| 7-8 | Passive | Ask what would make it a 10, feature request capture |\n| 0-6 | Detractor | CS outreach within 24h, root cause analysis |\n\n### 6. Retention Metrics Dashboard\n\n| Metric | Cadence | Target |\n|--------|---------|--------|\n| Logo retention (monthly) | Monthly | > 95% |\n| Net revenue retention | Monthly | > 110% |\n| Gross revenue retention | Monthly | > 90% |\n| Time to first value | Per cohort | < 24 hours |\n| DAU/MAU ratio | Weekly | > 40% = sticky product |\n| Support ticket CSAT | Weekly | > 90% |\n| Health score distribution | Weekly | < 20% in at-risk/critical |"
    },
    {
      "name": "affiliate-marketing",
      "description": "Affiliate program design, commission structures, partner recruitment, tracking implementation, and performance optimization.",
      "category": "growth",
      "features": [
        "Affiliate program structure design",
        "Commission model optimization (CPA, CPS, tiered)",
        "Partner recruitment and onboarding",
        "Tracking pixel and attribution setup",
        "Affiliate content and creative guidelines",
        "Performance reporting and payout automation"
      ],
      "useCases": [
        "Launch an affiliate program from scratch",
        "Design a tiered commission structure",
        "Set up affiliate tracking with proper attribution",
        "Recruit and onboard the first 50 affiliates"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Affiliate Marketing\n\n## Workflow\n\n### 1. Program Structure\n\n**In-house vs network:**\n\n| Factor | In-house | Network (ShareASale, Impact, etc.) |\n|--------|----------|-----------------------------------|\n| Setup cost | Higher (build tracking) | Lower (platform fee) |\n| Commission fee | None (just payouts) | 20-30% on top of commission |\n| Control | Full | Limited by platform rules |\n| Recruitment | You do it all | Access to affiliate marketplace |\n| Tracking | Custom or SaaS (Rewardful, FirstPromoter) | Built-in |\n| Best for | SaaS, high-value products | E-commerce, consumer products |\n\n**Recommendation:** Start in-house with a SaaS tracker (Rewardful, PartnerStack, FirstPromoter). Move to network only if you need volume affiliate recruitment.\n\n### 2. Commission Models\n\n| Model | Structure | Best for | Example |\n|-------|-----------|----------|---------|\n| CPA (Cost Per Acquisition) | Flat fee per signup/sale | SaaS free trials, lead gen | $50 per paid signup |\n| CPS (Cost Per Sale) | % of sale value | E-commerce, variable pricing | 20% of first purchase |\n| Recurring | % of subscription revenue | SaaS with monthly billing | 20% recurring for 12 months |\n| Tiered | Increasing % at volume thresholds | Motivating top performers | 20% (1-10), 25% (11-50), 30% (50+) |\n| Hybrid | Base CPA + recurring bonus | Balanced motivation | $25 CPA + 10% recurring |\n\n**Setting commission rates:**\n- Calculate your CAC from other channels\n- Set affiliate commission at 30-50% of your average CAC (profitable from day 1)\n- For SaaS: recurring commission should cap at 12 months (prevents perpetual liability)\n- Review rates quarterly based on affiliate-sourced LTV vs other channels\n\n### 3. Tracking Implementation\n\n**Server-side tracking (recommended \u2014 survives ad blockers):**\n```javascript\n// On referral click \u2014 store affiliate ID\napp.get('/ref/:affiliateId', (req, res) => {\n  res.cookie('affiliate_id', req.params.affiliateId, {\n    maxAge: 30 * 24 * 60 * 60 * 1000, // 30-day cookie\n    httpOnly: true,\n    secure: true,\n    sameSite: 'lax'\n  });\n  res.redirect('/');\n});\n\n// On conversion \u2014 attribute to affiliate\napp.post('/api/signup', async (req, res) => {\n  const affiliateId = req.cookies.affiliate_id;\n  if (affiliateId) {\n    await recordConversion({\n      affiliateId,\n      customerId: newUser.id,\n      value: plan.price,\n      type: 'signup'\n    });\n  }\n});\n```\n\n**Cookie window standards:**\n\n| Product type | Cookie window | Rationale |\n|-------------|--------------|-----------|\n| SaaS | 30-90 days | Longer consideration cycle |\n| E-commerce | 7-30 days | Shorter purchase cycle |\n| High-ticket | 90-180 days | Enterprise sales cycle |\n\n**Attribution rules:**\n- Last click wins (standard, simplest)\n- First click wins (rewards discovery, used by Amazon)\n- Linear (split credit) \u2014 complex, avoid unless needed\n- Direct traffic always overrides affiliate (prevent self-referral fraud)\n\n### 4. Partner Recruitment\n\n**Ideal affiliate profiles:**\n\n| Type | Characteristics | Approach |\n|------|----------------|----------|\n| Content creators | Blog/YouTube in your niche | Outreach with free product + custom commission |\n| Review sites | G2, Capterra, niche review blogs | Ensure listing, offer affiliate tracking |\n| Influencers | Social following in target audience | Custom landing page + higher commission |\n| Existing customers | Happy users with audience | In-app referral prompt + affiliate upgrade option |\n| Agencies | Serve your target market | Reseller/referral hybrid program |\n\n**Recruitment outreach template:**\n```\nSubject: Partner with [Product] \u2014 [X]% commission\n\nHi [Name],\n\nI've been following your content on [specific topic] \u2014 [genuine compliment].\n\nWe're building [Product], which helps [audience] with [value prop].\nI think it'd be a natural fit for your audience.\n\nOur affiliate program:\n- [X]% recurring commission (or flat $X per signup)\n- [X]-day cookie window\n- Dedicated affiliate dashboard\n- Custom landing pages and creatives\n\nInterested in trying it out? Happy to set you up with a free account\nand walk through the program.\n\n[Name]\n```\n\n### 5. Compliance\n\n**FTC disclosure requirements:**\n- Affiliates MUST disclose the relationship (\"I earn a commission if you buy through my link\")\n- Disclosure must be clear, conspicuous, and BEFORE the link\n- \"Ad\" or \"Sponsored\" labels on social media\n- Include disclosure guidelines in your affiliate agreement\n\n**Fraud prevention:**\n- Monitor for self-referrals (same IP for click and conversion)\n- Flag unusually high conversion rates (> 20% = suspicious)\n- Require minimum cookie age (> 1 second between click and conversion)\n- Ban coupon/deal sites from bidding on your brand keywords\n- Review top affiliates manually quarterly\n\n### 6. Performance Optimization\n\n**Monthly affiliate dashboard:**\n\n| Metric | Calculate | Benchmark |\n|--------|-----------|-----------|\n| Active affiliates | Affiliates with \u22651 conversion/month | 10-20% of total |\n| Revenue per affiliate | Total affiliate revenue / Active affiliates | Track trend |\n| Conversion rate | Conversions / Clicks | 2-5% (depends on niche) |\n| EPC (Earnings Per Click) | Total commissions / Total clicks | $0.50-2.00 |\n| Average commission | Total paid / Total conversions | Track vs CAC |\n| Affiliate-sourced % | Affiliate revenue / Total revenue | 10-30% target |\n\n**Top performer strategy:**\n- Identify top 10% of affiliates by revenue\n- Offer exclusive commission rates (+5-10%)\n- Provide early access to new features for content\n- Quarterly check-in call with affiliate manager\n- Custom creatives and co-branded landing pages"
    },
    {
      "name": "pricing-optimization",
      "description": "Price testing, value metric selection, packaging strategy, discount frameworks, and willingness-to-pay research.",
      "category": "conversion",
      "features": [
        "Van Westendorp price sensitivity analysis",
        "Conjoint analysis for feature packaging",
        "Value metric selection framework",
        "Discount strategy and guardrails",
        "Price localization and PPP adjustments",
        "Annual vs monthly pricing optimization"
      ],
      "useCases": [
        "Run a Van Westendorp survey and analyze results",
        "Select the right value metric for a SaaS product",
        "Design a discount strategy that protects margins",
        "Implement price localization by country"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Pricing Optimization\n\n## Workflow\n\n### 1. Value Metric Selection\n\nThe value metric is what you charge for. Get this wrong and everything else fails.\n\n**Good value metric criteria:**\n- Scales with value delivered to customer\n- Easy for customer to understand\n- Predictable for customer to budget\n- Grows as customer succeeds\n\n| Metric type | Examples | Best for |\n|-------------|----------|----------|\n| Per seat | $X/user/month | Collaboration tools |\n| Per usage | $X/API call, $X/GB | Infrastructure, API products |\n| Per feature | Tier-based access | Horizontal SaaS |\n| Per outcome | $X/lead, $X/transaction | Performance tools |\n| Flat rate | $X/month | Simple products |\n\n**Decision framework:**\n- If value scales linearly with users \u2192 per seat\n- If value scales with consumption \u2192 usage-based\n- If features differentiate segments clearly \u2192 tier-based\n- If you can measure outcomes \u2192 outcome-based\n- When in doubt \u2192 start with per seat (simplest)\n\n### 2. Van Westendorp Price Sensitivity\n\n**Survey questions (ask all 4):**\n1. At what price would this be **so cheap** you'd question the quality?\n2. At what price is this a **bargain** \u2014 great buy for the money?\n3. At what price is this **getting expensive** \u2014 you'd think twice?\n4. At what price is this **too expensive** \u2014 you'd never consider it?\n\n**Analysis:**\nPlot cumulative distributions of all 4 questions. Intersections give:\n\n| Intersection | Meaning |\n|-------------|---------|\n| \"Too cheap\" \u2229 \"Getting expensive\" | Point of marginal cheapness |\n| \"Bargain\" \u2229 \"Too expensive\" | Point of marginal expensiveness |\n| \"Too cheap\" \u2229 \"Too expensive\" | Optimal price point |\n| \"Bargain\" \u2229 \"Getting expensive\" | Indifference price point |\n\n**Acceptable price range:** Between marginal cheapness and marginal expensiveness.\n\n**Minimum sample:** 200 responses per segment for reliable results.\n\n### 3. Tier Design\n\n**3-tier standard (recommended starting point):**\n\n| Element | Starter | Professional | Enterprise |\n|---------|---------|-------------|------------|\n| Price anchor | Low (attract) | Medium (convert) | High (capture) |\n| Target | Individual / small team | Growing team | Large organization |\n| Value metric limit | Low | Medium | Unlimited or custom |\n| Support | Self-serve | Email + chat | Dedicated CSM |\n| Features | Core only | Core + advanced | All + custom |\n\n**Pricing rules:**\n- Professional should be 2-3x Starter price\n- Enterprise should be 3-5x Professional (or custom)\n- Professional tier should be the obvious \"best value\" (anchor effect)\n- Include one \"decoy\" feature in Professional that makes it clearly better than Starter\n- Enterprise always includes \"talk to sales\" \u2014 never self-serve\n\n### 4. Discount Strategy\n\n**Guardrails:**\n\n| Discount type | Max | Approval |\n|---------------|-----|----------|\n| Annual prepay | 20% | Self-serve |\n| Multi-year deal | 30% | Manager approval |\n| Competitive switch | 15% | Manager approval |\n| Volume (10+ seats) | 15% | Auto-calculated |\n| Strategic / Logo | 40% | VP approval + documented justification |\n\n**Rules:**\n- Never discount more than 40% (devalues product permanently)\n- Always trade something: discount for annual commitment, case study, referral\n- Track discount rate by rep (flag reps averaging > 20%)\n- Sunset discounts: \"This rate is locked for 12 months, then standard pricing\"\n- Document every discount reason in CRM\n\n### 5. Price Localization\n\n**Purchasing Power Parity (PPP) adjustments:**\n\n| Tier | Countries | Adjustment |\n|------|-----------|------------|\n| Full price | US, UK, Canada, Australia, Germany, France | 100% |\n| Tier 2 | Spain, Italy, Portugal, Czech Republic, Poland | 70-80% |\n| Tier 3 | Brazil, Mexico, Turkey, South Africa | 50-60% |\n| Tier 4 | India, Indonesia, Philippines, Nigeria | 30-40% |\n\n**Implementation:**\n- Use IP geolocation for initial pricing display\n- Allow currency switching (not just symbol \u2014 actual price adjustment)\n- Don't show the discount \u2014 just show the local price\n- Gate enterprise features at full price regardless of region\n\n### 6. Annual vs Monthly\n\n**Best practices:**\n- Default to annual on pricing page (show monthly price as comparison)\n- Annual discount: 15-20% (2 months free is standard messaging)\n- Show monthly price per-month even for annual (\"$49/mo billed annually\")\n- Offer monthly-to-annual upgrade path with prorated credit\n- Track annual vs monthly mix (target: 60%+ annual for predictable revenue)\n\n### 7. Price Increase Playbook\n\n**Communication timeline:**\n\n| When | Action |\n|------|--------|\n| 90 days before | Internal alignment: sales, CS, support briefed |\n| 60 days before | Email announcement to all customers (clear, empathetic) |\n| 30 days before | Reminder email + lock-in offer (annual at current price) |\n| Day of | Price change live + support team ready for questions |\n| 30 days after | Review churn impact, adjust if needed |\n\n**Email template:**\n```\nSubject: Changes to your [Product] plan\n\nHi [Name],\n\nOn [date], we're updating our pricing. Your plan will change\nfrom $X/mo to $Y/mo.\n\nWhy: [Honest reason \u2014 new features, increased costs, market alignment].\n\nWhat you can do:\n- Lock in current pricing by switching to annual before [date]\n- Upgrade to [plan] to get [specific new value] at the new rate\n- Questions? Reply to this email \u2014 we're here to help.\n\n[Name], [Title]\n```\n\n**Expected impact:** Well-communicated 10-20% increase typically sees < 2% incremental churn. Poorly communicated or >30% increase can see 5-10%+ churn."
    },
    {
      "name": "customer-acquisition",
      "description": "CAC optimization, channel mix modeling, attribution analysis, and acquisition strategy for paid and organic channels.",
      "category": "growth",
      "features": [
        "CAC calculation and benchmarking",
        "Channel mix modeling and budget allocation",
        "Attribution model comparison",
        "Organic vs paid acquisition analysis",
        "Payback period optimization",
        "LTV:CAC ratio tracking"
      ],
      "useCases": [
        "Calculate and optimize customer acquisition cost",
        "Model budget allocation across acquisition channels",
        "Compare attribution models for decision-making",
        "Build an LTV:CAC dashboard for board reporting"
      ],
      "version": "1.0.0",
      "color": "888888",
      "platforms": [
        "openclaw",
        "claude-code",
        "cursor",
        "codex"
      ],
      "installs": 0,
      "content": "# Customer Acquisition\n\n## Workflow\n\n### 1. CAC Calculation\n\n**Blended CAC (company-level):**\n```\nBlended CAC = (Total Sales + Marketing spend) / New customers acquired\n```\n\n**Per-channel CAC (more actionable):**\n```\nChannel CAC = Channel spend (ads + tools + headcount allocation) / Customers from that channel\n```\n\n**Fully-loaded CAC (most accurate):**\n```\nFully-loaded CAC = (Ad spend + Sales salaries + Marketing salaries + Tools + Agency fees + Content production) / New customers\n```\n\n**What to include:**\n\n| Include | Don't include |\n|---------|---------------|\n| Ad spend (all platforms) | Product development costs |\n| Sales team compensation (base + commission) | Customer success costs |\n| Marketing team compensation | Infrastructure/hosting |\n| Marketing tools (HubSpot, analytics, etc.) | General overhead (rent, legal) |\n| Content production costs | |\n| Agency/contractor fees | |\n| Event/sponsorship costs | |\n\n### 2. Channel Evaluation\n\n**Scoring matrix \u2014 rate each channel:**\n\n| Channel | CAC | Scalability | Time to result | LTV of acquired customers | Total score |\n|---------|-----|-------------|---------------|--------------------------|-------------|\n| Organic search | $50 | High | 6-12 months | High | |\n| Paid search (Google) | $150 | High | Immediate | Medium | |\n| Paid social (Meta) | $120 | High | 1-2 weeks | Medium | |\n| LinkedIn ads | $250 | Medium | 1-2 weeks | High (B2B) | |\n| Content marketing | $80 | High | 3-6 months | High | |\n| Referral program | $30 | Medium | 1-3 months | Very high | |\n| Cold outreach | $100 | Medium | 2-4 weeks | High (if targeted) | |\n| Partnerships | $60 | Low-Medium | 3-6 months | High | |\n| Events/conferences | $300 | Low | 1-3 months | High | |\n| Product-led (viral) | $10 | Very high | Varies | Varies | |\n\n### 3. Attribution Models\n\n| Model | How it works | Best for | Bias |\n|-------|-------------|----------|------|\n| First touch | 100% credit to first interaction | Understanding discovery | Over-credits awareness channels |\n| Last touch | 100% credit to last interaction | Understanding conversion | Over-credits bottom-funnel |\n| Linear | Equal credit to all touchpoints | Simple multi-touch | Treats all touches equally (unrealistic) |\n| Time decay | More credit to recent touchpoints | Long sales cycles | Under-credits awareness |\n| Position-based (U-shape) | 40% first, 40% last, 20% middle | Balanced view | Arbitrary weights |\n| Data-driven | ML-based, dynamic weights | Large datasets (1000+ conversions) | Black box |\n\n**Recommendation:** Run first-touch AND last-touch in parallel. Compare results. If they agree on a channel, you have high confidence. If they disagree, dig deeper into that channel.\n\n### 4. LTV:CAC Analysis\n\n**Benchmarks by stage:**\n\n| Metric | Seed/Early | Series A | Series B+ |\n|--------|-----------|----------|-----------|\n| LTV:CAC ratio | > 2:1 | > 3:1 | > 4:1 |\n| CAC payback | < 18 months | < 12 months | < 8 months |\n| CAC as % of first-year ACV | < 100% | < 80% | < 60% |\n\n**By segment:**\n\n| Segment | Typical CAC | Typical LTV | Target LTV:CAC |\n|---------|-------------|-------------|----------------|\n| Self-serve SMB | $50-200 | $500-2,000 | > 5:1 |\n| Inside sales mid-market | $500-2,000 | $5,000-30,000 | > 3:1 |\n| Enterprise field sales | $5,000-50,000 | $50,000-500,000 | > 3:1 |\n\n**Payback period:**\n```\nPayback (months) = CAC / (Monthly ARPU \u00d7 Gross margin %)\n```\n\n### 5. Channel Saturation Signals\n\n**When to diversify (channel is saturating):**\n- CAC increased >20% in 3 months with no strategy change\n- Impression share hitting ceiling (Google Ads > 90%)\n- Frequency > 3x on paid social (audience fatigue)\n- Organic traffic plateau despite continued investment\n- Diminishing returns on spend increase (2x budget \u2260 2x results)\n\n**Response:**\n1. Optimize existing channel before abandoning\n2. Test new channel with 10-15% of budget\n3. Run for 60-90 days before evaluating\n4. Compare new channel CAC and LTV to established channels\n5. Scale if CAC is within 1.5x of best-performing channel\n\n### 6. Budget Allocation Framework\n\n**Portfolio approach:**\n\n| Category | % of budget | Purpose |\n|----------|------------|---------|\n| Proven channels | 60-70% | Channels with known, acceptable CAC |\n| Scaling channels | 20-25% | Channels showing promise, increasing spend |\n| Experimental | 10-15% | New channels, testing hypotheses |\n\n**Rebalance quarterly:**\n- Move budget from declining-ROI channels to improving ones\n- Kill experiments that haven't shown promise in 90 days\n- Double down on channels where LTV:CAC is improving\n\n### 7. Acquisition Dashboard\n\n| Metric | Cadence | View |\n|--------|---------|------|\n| Blended CAC | Monthly | Trend line, 6-month rolling |\n| Channel CAC | Monthly | Per-channel bar chart |\n| LTV:CAC by channel | Quarterly | Stacked comparison |\n| Payback period | Monthly | Trend vs target |\n| New customer count by source | Weekly | Stacked area chart |\n| CAC efficiency (CAC / ARPU) | Monthly | Track improvement |\n| Pipeline contribution by channel | Weekly | Marketing \u2192 Sales attribution |"
    }
  ]
}